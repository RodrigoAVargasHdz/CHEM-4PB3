{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1CxFVk82NFVhdX9oXl03p7dEjK-lrGBcE?usp=sharing)\n",
        "\n",
        "# **Week 3 - Introduction to Linear Kinetic Models - Solutions**"
      ],
      "metadata": {
        "id": "L3Y2ZKRlFTZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Solution - Leave One Out (LOO)**"
      ],
      "metadata": {
        "id": "MbrAuMbzHrXV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_xkv5c4FM2Z"
      },
      "outputs": [],
      "source": [
        "#Make sure to run this code in an env where the model is initialized\n",
        "\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "# Initialize Leave One Out cross-validation\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Store the RMSE for each cross-validation step\n",
        "rmse_loo = []\n",
        "\n",
        "# Iterate over each cross-validation split\n",
        "for train_index, val_index in loo.split(X):\n",
        "    X_train, y_train = X[train_index], y[train_index]\n",
        "    X_val, y_val = X[val_index], y[val_index]\n",
        "\n",
        "    # Train the model and calculate RMSE for the current split\n",
        "    w = linear_model_solver((X_train, y_train), deg, l)\n",
        "    y_val_pred = f_poly(X_val, w, deg)\n",
        "    rmse = f_rmse(y_val, y_val_pred)\n",
        "\n",
        "    rmse_loo.append(rmse)\n",
        "\n",
        "# Calculate the average RMSE across all LOO splits\n",
        "average_rmse_loo = sum(rmse_loo) / len(rmse_loo)\n",
        "print(f'Average RMSE from Leave One Out (LOO) Cross-Validation: {average_rmse_loo}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Solution - Try your own**"
      ],
      "metadata": {
        "id": "pdNtJddaHx1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the cross_val_score function\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Create a pipeline that includes polynomial feature transformation and ridge regression\n",
        "model = make_pipeline(PolynomialFeatures(degree=deg), Ridge(alpha=l))\n",
        "\n",
        "# Perform cross-validation\n",
        "# Here, we use negative mean squared error as our scoring parameter because cross_val_score expects a utility function\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Calculate RMSE from the cross-validation scores\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "# Print the average RMSE\n",
        "print(f'Average RMSE from cross-validation: {np.mean(rmse_scores)}')\n"
      ],
      "metadata": {
        "id": "8x6NNok4FS7v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}