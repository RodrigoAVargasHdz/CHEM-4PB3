{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpHmTbShMO89"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/RodrigoAVargasHdz/CHEM-4PB3/blob/w2024/Course_Notes/Week%203/Week_3_Intro_Linear_Models.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# **Week 3 - Introduction to Linear Models**\n",
        "\n",
        "## **Abstract**\n",
        "\n",
        "1. **Brief Overview of Parameter Generation**: Creating an array of random integers and adding Gausian Noise to data using **NumPy's** `Uniform` function.  \n",
        "\n",
        "2. **Animations on Google Colab**: Introducing the `IPython.display` to create gifs using individual frames. These can be used to visualize Kinetic Models in Python.\n",
        "\n",
        "3. **Linear and Polynomial Models**: The use of Linear and Polynomial models to predict data, inspecting the advantages and distadvantages of each model. Introducing the mathmatical structure of these models.\n",
        "\n",
        "4. **Overfitting and Underfitting**: Overfitting  occurs when a model learns the training data too well, capturing noise and irrelevant details, which leads to poor generalization to new data. Underfitting, occurs when a model is too simple to capture the underlying patterns in the data, resulting in a lack of accuracy both on the training and test data.\n",
        "\n",
        "5. **Understanding Lambda and Regularization**: To avoid overfitting or underfitting data, lambda are introduced as critical elements in machine learning. Introducing the magnitudes of the coefficient to optimize regularization.\n",
        "\n",
        "\n",
        ">## **References: Essential Resources for Further Learning**\n",
        ">\n",
        ">1. **NumPy Random Tutorial**: [Tutorial](https://numpy.org/doc/stable/reference/random/index.html)\n",
        "2. **Creating Animations with Matplotlib**: [Tutorial](https://towardsdatascience.com/animations-with-matplotlib-d96375c5442c)\n",
        "3. **Linear Regression in Python**: [Tutorial](https://realpython.com/linear-regression-in-python/)\n",
        "4. **Overfitting and Underfitting in Machine Learning**: [Article](https://towardsdatascience.com/overfitting-vs-underfitting-a-complete-example-d05dd7e19765)\n",
        "5. **Regularization in Machine Learning**: [Tutorial](https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net)\n",
        "\n",
        "\n",
        "Feel free to explore these resources to deepen your understanding of data visualization, data management, and computational tools in Chemistry.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3SPUNHjwhHf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML, Image # For GIF\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADCJ63YVMnhx"
      },
      "source": [
        "## **Understanding Linear Models in Python - Animation**\n",
        "\n",
        "To visualize Linear Kinetic Models in Python, we can generate random data using **NumPy's** `Uniform` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05GPnAEhwiwc"
      },
      "outputs": [],
      "source": [
        "# generate random data over f(x) = sin(x) + x - 1\n",
        "def get_data(N):\n",
        "    x = np.linspace(-1.,1.,N) #This creates an array x of N linearly spaced values between -1 and 1.\n",
        "    y = np.sin(.5*x) + x -1.\n",
        "    y = y + np.random.uniform(low = 0.,high=0.5,size=x.shape) #Adds random noise to each y value.\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Linear models 101:\n",
        "$$\n",
        "\\begin{align}\n",
        "f(x) &= m x + b\n",
        "=  \\sum_{i=0}^{d} w_i x_i = \\begin{bmatrix}\n",
        "w_0 & w_1 & \\cdots & w_p \\\\\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        " 1 \\\\\n",
        " x_1 \\\\\n",
        " \\vdots \\\\\n",
        " x_d\n",
        "\\end{bmatrix}\n",
        "\\end{align} \n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "jdP4jTIrwlxV",
        "outputId": "a1dbef26-6998-4c87-ed4f-68f3adc27315"
      },
      "outputs": [],
      "source": [
        "def model(x,params):\n",
        "    m,b = params #tuple\n",
        "    y = m*x\n",
        "    y = y + b\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3uCgKm4wt-r"
      },
      "source": [
        "### **Generating Random Parameters**\n",
        "\n",
        "*   **Purpose:** The purpose of this function is to generate a 2D matrix of random numbers. The dimensions of this array are $m x 2$, meaning there are m rows and 2 columns.\n",
        "\n",
        "- $$[m,b] \\sim U([-2,2])$$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ_UYrm_wwX3"
      },
      "outputs": [],
      "source": [
        "#random parameters\n",
        "def get_random_params(m):\n",
        "    theta_random = np.random.uniform(low=-2.,high=2.,size=(m,2))\n",
        "    return theta_random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Funcitons in Python**\n",
        "\n",
        "1. Build-in functions: `min(x)`\n",
        "2. User-Defined Functions: \n",
        "   ```python\n",
        "      def f_min(x): \n",
        "         return np.min(x)\n",
        "   ```\n",
        "3. lambda functions: \n",
        "   ```python\n",
        "   lambda x: np.min(x)\n",
        "   ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f_min = lambda x: np.min(x) \n",
        "x = np.array([10.,1.,2.,3.])\n",
        "print(type(f_min))\n",
        "print(f_min(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exercise**<br>\n",
        "Write a lambda function for a linear model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#code here!\n",
        "model_l = lambda x,m,b: m*x+b\n",
        "m = 1.\n",
        "b = 2.\n",
        "x = 10.\n",
        "\n",
        "print(model(x,(m,b)))\n",
        "print(model_l(x,m,b))\n",
        "\n",
        "model_l2 = lambda x: model(x,(m,b))\n",
        "print(model_l2(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXT7WNatw1C3"
      },
      "source": [
        "## **Figure Per Frame**\n",
        "\n",
        "\n",
        "> The model will plot a series of linear models based on the parameters.\n",
        "\n",
        "> Loops over each pair of parameters **`(m, b)`** in `theta_rnd`.\n",
        "For each pair, it calls `plot_figure_frame` to plot the data and the linear model based on those parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> This graph shows the datapoints generated. Using Python and Linear Regression, we can fit a model (a line of best fit) to the datapoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x, y = get_data(25)\n",
        "plt.scatter(x, y, label='data')\n",
        "plt.xlabel(r'$x$', fontsize=18)\n",
        "plt.ylabel(r'$f(x)$', fontsize=18)\n",
        "plt.ylim(-3., 2.)\n",
        "plt.legend()\n",
        "# plt.savefig('Figures/data.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_figure_frame(data, params, i):\n",
        "    m, b = params\n",
        "    x, y = data\n",
        "    def f(x, m, b): return m*x + b\n",
        "\n",
        "    x_grid = np.linspace(-1., 1., 100)\n",
        "    y_pred = f(x_grid, m, b)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.clear()\n",
        "    ax.scatter(x, y, label='data')\n",
        "    ax.plot(x_grid, y_pred, color='k', label='model')\n",
        "    ax.text(0.2, -2.5, 'm=%.2f, b=%.2f' % (m, b), fontsize=15)\n",
        "    ax.legend(loc=1)\n",
        "    ax.set_xlabel(r'$x$', fontsize=18)\n",
        "    ax.set_ylabel(r'$f(x)$', fontsize=18)\n",
        "    ax.set_ylim(-3., 2.)\n",
        "    # plt.savefig('Figures/linear_model_%s.png'%(i))\n",
        "    plt.draw()\n",
        "    plt.pause(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i80tlPyxzskR",
        "outputId": "917a7047-a8b5-4e88-e897-384837602714"
      },
      "outputs": [],
      "source": [
        "theta_rnd = get_random_params(2)\n",
        "x, y = get_data(25)\n",
        "for i, p in enumerate(theta_rnd):\n",
        "    plot_figure_frame((x,y),p,i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aTsZK-C08uL"
      },
      "source": [
        "## **Animation**\n",
        "\n",
        "> To animate the Linear model in Google Colab, the [`IPython.display`](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html) library can convert frames to gifs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "31pK2DzX1FGS",
        "outputId": "fd42bb76-66ed-4c54-996c-071b3995db49"
      },
      "outputs": [],
      "source": [
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML\n",
        "\n",
        "x,y = get_data(25)\n",
        "theta_rnd = get_random_params(20)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,5))\n",
        "# plt.figure(facecolor='white')\n",
        "\n",
        "ax.set_xlabel(r'$x$', fontsize=18)\n",
        "ax.set_ylabel(r'$f(x)$', fontsize=18)\n",
        "ax.set_ylim(-3., 2.)\n",
        "ax.set_xlim(-1.1, 1.1)\n",
        "ax.scatter(x,y,label='data')\n",
        "\n",
        "# line1, = ax.plot([], [], ms=20, label='data')\n",
        "line2, = ax.plot([], [], ms=20, color='k', label='model')\n",
        "txt2 = ax.text(0.2,-2.5, '',fontsize=15)\n",
        "ax.legend(loc=1)\n",
        "\n",
        "def drawframe(n):\n",
        "    params = theta_rnd[n]\n",
        "    m, b = params\n",
        "    def f(x, m, b): return m*x + b\n",
        "\n",
        "    x_grid = np.linspace(-1., 1., 100)\n",
        "    y_pred = f(x_grid, m, b)\n",
        "\n",
        "    # line1.set_data(x,y)\n",
        "    line2.set_data(x_grid,y_pred)\n",
        "    txt2.set_text('m=%.2f, b=%.2f'%(m,b))\n",
        "\n",
        "    return (line2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGgMO8HNRo5h"
      },
      "source": [
        "> The original plotted data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "nuwpvbzO1Mxf",
        "outputId": "bdcc58e4-74e0-4511-b34f-ad9123e621c9"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# blit=True re-draws only the parts that have changed.\n",
        "anim = animation.FuncAnimation(\n",
        "    fig, drawframe, frames=19, interval=200, blit=False,)\n",
        "\n",
        "# Save as GIF\n",
        "anim.save('animation.gif')  # writer='pillow'\n",
        "\n",
        "# play animation\n",
        "HTML(anim.to_html5_video())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0V4mzWILekw"
      },
      "source": [
        "## **Polynomials Models are linear Models**\n",
        "\n",
        "Polynomial models are a class of regression models that use polynomial functions to fit a relationship between a dependent variable and **one or more independent variables**. Unlike linear models, which are constrained to a straight line, polynomial models can **fit data with curves and complex** relationships, making them more flexible for a wide range of datasets.\n",
        "\n",
        "\n",
        "- **General Form**: The general form of a polynomial model is given by:\n",
        "  $$\n",
        "    f(x) = w_0 + w_1x + w_2x^2 + \\ldots + w_px^p = \\begin{bmatrix}\n",
        "    w_0 & w_1 & \\cdots & w_p \\\\\n",
        "    \\end{bmatrix} \\begin{bmatrix}\n",
        "    1 \\\\\n",
        "    x^1 \\\\\n",
        "    \\vdots \\\\\n",
        "    x^p\n",
        "      \\end{bmatrix}\n",
        "  $$\n",
        "    where:\n",
        "    - $x$ is the independent variable.\n",
        "    - $w_0, w_1, \\ldots, w_n$ are the coefficients of the model.\n",
        "    - $n$ is the degree of the polynomial.\n",
        "\n",
        "- **Degree of the Polynomial**:\n",
        "  - The degree $n$ of the polynomial determines the curve's complexity.\n",
        "  - A degree of 1 corresponds to a linear model (straight line).\n",
        "  - Higher degrees (2 for quadratic, 3 for cubic, etc.) allow for more complex curves.\n",
        "\n",
        "\n",
        "- **Flexibility**:\n",
        "  - Polynomial models are more flexible than linear models, able to fit data with curves and **non-linear relationships**.\n",
        "\n",
        "\n",
        "- **Overfitting Concern**:\n",
        "  - Caution is needed to avoid overfitting, especially with high-degree polynomials.\n",
        "  - Overfitting occurs when the model becomes too complex, fitting the noise in the data rather than the underlying trend.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "9n34K19ymdD_",
        "outputId": "041e9c46-41dd-4cc9-f3b1-260789aa8cca"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML\n",
        "\n",
        "# New function to generate data\n",
        "def get_data(N):\n",
        "    x = np.linspace(-2, 2, N)\n",
        "    y = np.sin(x**3) * np.cos(x) - x**3\n",
        "    y += np.random.normal(scale=1, size=x.shape)  # Adding Gaussian noise\n",
        "    return x, y\n",
        "\n",
        "# Generate data\n",
        "x, y = get_data(20)\n",
        "\n",
        "# Set up the figure, the axis, and the plot element\n",
        "fig, ax = plt.subplots()\n",
        "# ax.set_xlim((min(x), max(x)))\n",
        "# ax.set_ylim((min(y)-1, max(y)+1))\n",
        "\n",
        "# Plot the data points\n",
        "ax.scatter(x, y, color='red')\n",
        "\n",
        "\n",
        "\n",
        "# # Frame by frame\n",
        "for pi in range(1,20,2): \n",
        "    z = np.polyfit(x, y, pi)  # what is this?\n",
        "    poly_model = np.poly1d(z)  # what is this?\n",
        "    ax.plot(x, poly_model(x),label='p = %s' % pi)\n",
        "    # break\n",
        "plt.legend()\n",
        "plt.show()\n",
        "    \n",
        "\n",
        "# # Animation function\n",
        "# # Initialization function: plot the background of each frame\n",
        "# line, = ax.plot([], [], lw=2)\n",
        "# def init():\n",
        "#     line.set_data([], [])\n",
        "#     return (line,)\n",
        "# def animate(i):\n",
        "#     if i == 0:\n",
        "#         return (line,)\n",
        "#     z = np.polyfit(x, y, i) #what is this? \n",
        "#     poly_model = np.poly1d(z) #what is this?\n",
        "#     line.set_data(x, poly_model(x))\n",
        "#     ax.set_title(f\"Polynomial Degree {i}\")\n",
        "#     return (line,)\n",
        "\n",
        "# # Call the animator\n",
        "# anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "#                                frames=15, interval=200, blit=True)\n",
        "\n",
        "# # Display the animation\n",
        "# HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuhkYgNQLLie"
      },
      "outputs": [],
      "source": [
        "# polynomial model 1D\n",
        "def poly_pred(data_tr, deg, x_grid):\n",
        "    x, y = data_tr\n",
        "\n",
        "    #training \n",
        "    w = np.polyfit(x, y, deg)\n",
        "    poly_model = np.poly1d(w) \n",
        "\n",
        "    #prediction\n",
        "    y_pred = poly_model(x_grid)\n",
        "    return y_pred,w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "PMUU4zC1LPLq",
        "outputId": "b95b0291-1634-4889-b730-c084b6a212a6"
      },
      "outputs": [],
      "source": [
        "x, y = get_data(10)\n",
        "data_tr = (x,y)\n",
        "x_grid = np.linspace(-2., 2., 200)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "w_ = [] \n",
        "p_ = np.arange(1, 13, 1,dtype=np.int32)\n",
        "for p in p_: # loop over different degrees\n",
        "    y_pred, w = poly_pred(data_tr, p, x_grid)\n",
        "    print(p,w)\n",
        "    plt.plot(x_grid,y_pred,label='p=%s'%p)\n",
        "    w_.append(np.pad(w, (0, 13-w.shape[0]),\n",
        "              mode='constant', constant_values=0))\n",
        "plt.scatter(x,y,s=75,label='data')\n",
        "plt.legend(fontsize=5)\n",
        "plt.xlabel(r'$x$',fontsize=18)\n",
        "plt.ylabel(r'$f(x)$',fontsize=18)\n",
        "# plt.savefig('Figures/polyfit_2.png',dpi=1800)\n",
        "\n",
        "fig, ax0 = plt.subplots(1, 1)\n",
        "c = ax0.pcolor(np.abs(np.array(w_)), edgecolors='k', linewidths=4)\n",
        "fig.colorbar(c, ax=ax0,label=r'$|w_i|$')\n",
        "ax0.set_xlabel(r'$w_i$')\n",
        "ax0.set_yticks(np.arange(p_.shape[0])+0.5, p_)\n",
        "ax0.set_ylabel('Poly degree')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
