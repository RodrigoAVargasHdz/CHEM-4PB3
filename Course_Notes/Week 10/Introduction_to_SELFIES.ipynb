{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1AlMwZ1Q3oH"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit py3Dmol\n",
        "!pip install selfies\n",
        "!pip install crem\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-ZGxTCHOMt1"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/RodrigoAVargasHdz/CHEM-4PB3/blob/w2024/Course_Notes/Week%2010/Introduction_to_SELFIES.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPTB593cOJss"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Draw, rdDepictor\n",
        "from rdkit.Chem import PandasTools, Descriptors\n",
        "import py3Dmol\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "from rdkit.Chem.Draw import rdMolDraw2D\n",
        "from IPython.display import SVG\n",
        "\n",
        "import selfies as sf\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from crem.crem import mutate_mol, grow_mol, link_mols\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQwW3Hkjkihb"
      },
      "source": [
        "# Mutations of molecules #\n",
        "\n",
        "\n",
        "Mutations in SMILES strings are a fundamental technique in computational chemistry and drug discovery for exploring the vast chemical space in search of novel molecules with desirable properties. <br>\n",
        "By introducing random or targeted changes to the SMILES representation of molecules, researchers can generate new molecular structures that may exhibit improved biological activity, selectivity, or pharmacokinetic properties. This process, inspired by the principles of natural evolution and genetic variation, enables the iterative refinement of molecular candidates through cycles of mutation, evaluation, and selection. It's a powerful approach for optimizing existing drugs, discovering new therapeutic candidates, and understanding the relationship between molecular structure and biological function, ultimately accelerating the pace of pharmaceutical development and the discovery of novel materials. <br>\n",
        "\n",
        "In this example, we’re not only converting the SMILES string `CCO` into a molecule object but also ensuring its validity through sanitization. If we set `sanitize=False` in `Chem.MolFromSmiles`, then we don’t need to to explicitly call Chem.SanitizeMo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZqbkKuMksUy"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "# Replace 'YOUR_SMILES_STRING' with an actual SMILES string\n",
        "smile = 'CCO'\n",
        "\n",
        "# Convert SMILES to molecule object with sanitize=False\n",
        "molecule = Chem.MolFromSmiles(smile, sanitize=False)\n",
        "\n",
        "# Check if the conversion was successful\n",
        "if molecule is not None:\n",
        "    print(\"Molecule object created successfully!\")\n",
        "\n",
        "    # Sanitize the molecule for validation\n",
        "    Chem.SanitizeMol(molecule)\n",
        "\n",
        "    # Check if sanitization was successful\n",
        "    if Chem.SanitizeMol(molecule) == 0:\n",
        "        print(\"Molecule sanitized successfully!\")\n",
        "    else:\n",
        "        print(\"invalid chemistry\")\n",
        "else:\n",
        "    print(\"invalid SMILES\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brahEXHImbDg"
      },
      "source": [
        "The following code demonstrates how to replace a dummy atom in a molecule with a real atom using RDKit. This example assumes you have a molecule with at least one dummy atom (denoted as * in SMILES) that you want to replace with another atom or group:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZj745qqmlXi"
      },
      "outputs": [],
      "source": [
        "def replace_ghost_atom(smiles, replacement_smiles, atom_idx=None):\n",
        "    \"\"\"\n",
        "    Replaces a dummy atom in a molecule with a specified atom or group.\n",
        "\n",
        "    :param smiles: SMILES string of the original molecule containing a dummy atom.\n",
        "    :param replacement_smiles: SMILES string of the atom or group to replace the dummy atom.\n",
        "    :param atom_idx: Index of the dummy atom to replace. If None, replaces the first dummy atom found.\n",
        "    :return: SMILES string of the modified molecule, or None if the operation fails.\n",
        "    \"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    replacement_mol = Chem.MolFromSmiles(replacement_smiles)\n",
        "\n",
        "    if not mol or not replacement_mol:\n",
        "        return None\n",
        "\n",
        "    # Find the dummy atoms\n",
        "    dummy_atoms = [atom.GetIdx() for atom in mol.GetAtoms() if atom.GetSymbol() == '*']\n",
        "    if not dummy_atoms:\n",
        "        return None\n",
        "\n",
        "    # Select the dummy atom to replace\n",
        "    if atom_idx is not None and atom_idx in dummy_atoms:\n",
        "        dummy_atom_idx = atom_idx\n",
        "    else:\n",
        "        dummy_atom_idx = dummy_atoms[0]  # Default to the first dummy atom\n",
        "\n",
        "    # Replace the dummy atom\n",
        "    editable_mol = Chem.EditableMol(mol)\n",
        "    editable_mol.ReplaceAtom(dummy_atom_idx, replacement_mol.GetAtomWithIdx(0))\n",
        "    modified_mol = editable_mol.GetMol()\n",
        "\n",
        "    # Sanitize the molecule (optional but recommended)\n",
        "    Chem.SanitizeMol(modified_mol)\n",
        "\n",
        "    return Chem.MolToSmiles(modified_mol)\n",
        "\n",
        "# Example usage\n",
        "original_smiles = \"C1=CC=CC=C1*\"  # Benzene with a dummy atom\n",
        "# replacement_smiles = \"O\"  # Replace dummy atom with oxygen\n",
        "possible_characters = ['c','C', 'O', 'N', '=', '#', '(', ')','=O','#N','=N']\n",
        "good_molecules = [original_smiles]\n",
        "for ci in possible_characters:\n",
        "  modified_smiles = replace_ghost_atom(original_smiles, ci)\n",
        "  print(f\"Original SMILES: {original_smiles}\",f\"Modified SMILES: {modified_smiles}\")\n",
        "  if modified_smiles is not None:\n",
        "    good_molecules.append(modified_smiles)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUOhPjuYnE2x"
      },
      "outputs": [],
      "source": [
        "print(good_molecules)\n",
        "mol_good_molecules = [Chem.MolFromSmiles(si, sanitize=False) for si in good_molecules]\n",
        "\n",
        "img = Draw.MolsToGridImage(mol_good_molecules, molsPerRow=10, subImgSize=(500, 500), legends=good_molecules)\n",
        "img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bujcGhQYPD1g"
      },
      "source": [
        "# SELFIES #\n",
        "# **Introduction to SELFIES**\n",
        "\n",
        "Chemistry and computational analysis often grapple with the complexity of molecular representation. SELFIES (Self-Referencing Embedded Strings) is a robust molecular string representation system designed for unambiguous molecular encoding. Its key advantage lies in facilitating direct input into machine learning models, such as generative models, and ensuring the validity of the outputs.\n",
        "\n",
        "## **Key Points of SELFIES**\n",
        "\n",
        "- Robustness: Each SELFIES string is a valid molecular structure, overcoming the validity issues of other formats.\n",
        "- Generative Model Compatibility: SELFIES offers a diverse array of valid molecules, enhancing generative model outcomes.\n",
        "- Adjustable Constraints: The framework can impose both meaningful and arbitrary rule sets, showcasing its adaptability.\n",
        "- Syntax and Grammar: SELFIES uses a context-free grammar with specific symbols for atoms, rings, branches, and more.\n",
        "\n",
        "<br>\n",
        "\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <style>\n",
        "        .centered-image {\n",
        "            display: block;\n",
        "            margin-left: auto;\n",
        "            margin-right: auto;\n",
        "            width: 50%;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<a href=\"https://aspuru.substack.com/p/molecular-graph-representations-and\" target=\"_blank\">\n",
        "    <img src=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6e37c68a-a71c-4ffa-ba5c-ffe1e237a5c3_1600x859.png\"\n",
        "         alt=\"SMILES and SELFIES compared.\"\n",
        "         class=\"centered-image\">\n",
        "</a>\n",
        "\n",
        "<br>\n",
        "<figcaption align = \"center\"><b>Figure 1 - SMILES and SELFIES compared. Figure from\n",
        "Alan Aspuru-Guzik.</b></figcaption>\n",
        "\n",
        "\n",
        "## **Pros and Cons of SELFIES:**\n",
        "\n",
        "### **Pros of SELFIES:**\n",
        "- **Consistency**: SELFIES ensures that each molecule is represented by a unique string, which aids in maintaining database integrity and simplifying molecule comparisons.\n",
        "- **Generative Model Synergy**: Training with SELFIES results in a higher diversity of valid, novel molecules compared to SMILES, benefiting the exploration of chemical space.\n",
        "\n",
        "### **Cons of SELFIES:**\n",
        "- **Complexity**: The SELFIES syntax is more complex and less human-readable than SMILES, which can be a barrier for manual handling and interpretation.\n",
        "- **Adoption**: While gaining popularity, SELFIES is newer and less widespread than SMILES, potentially leading to compatibility issues with existing systems.\n",
        "\n",
        "\n",
        "\n",
        "## **Rules:**\n",
        "1. The main string is derived using a rule set such that the number of valence bonds per atom does not exceed physical limits.\n",
        "2. The symbol after a `Branch` is interpreted as the number of\n",
        "SELFIES symbols derived inside the branch.\n",
        "3. The symbol after `Ring` interpreted as a number too, indicating that the current atom is connected to the `(N + 1)`st previous atom.\n",
        "Thereby every information in the string (except the ring\n",
        "closure) is local and allows for efficient derivation rules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAkKNqvJPHsx"
      },
      "source": [
        "## **SELFIES vs. SMILES Representation**\n",
        "\n",
        "In chemical informatics, SELFIES and SMILES are two methods used for representing molecules as strings. While SMILES is the more traditional format, SELFIES is a newer format designed to overcome some of the limitations of SMILES.\n",
        "\n",
        "\n",
        "## **Symbol Indexing in SELFIES**\n",
        "\n",
        "The SELFIES format uses indexed symbols, such as `[Branch1]` or `[Ring1]`, which refer to specific structural elements. All other symbols are assigned index 0 by default. For example:\n",
        "- `[Branch1][size=1]` indicates a branch of size index+1\n",
        "- `[Ring2]` denotes a ring closure\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnNgyT6RPKEf"
      },
      "source": [
        "## **Using SELFIES:**\n",
        "SELFIES excel in generating random molecules and one-hot encoding for machine learning using valid SELFIE alphabets and external information such as ring structures.\n",
        "\n",
        "> The following code has been adopted and added from [Akshat Nigam &\n",
        "Aspuru-Guzik group's GitHub](https://github.com/aspuru-guzik-group/selfies_tutorial/tree/master)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWbbiGcfPNEI"
      },
      "outputs": [],
      "source": [
        "# import selfies as sf\n",
        "\n",
        "# List of molecules with their common names and SMILES representation\n",
        "molecules = [\n",
        "    (\"Benzene\", \"c1ccccc1\"),\n",
        "    (\"Caffeine\", \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"),\n",
        "    (\"Aspirin\", \"CC(=O)OC1=CC=CC=C1C(=O)O\"),\n",
        "    (\"Methane\", \"C\"),\n",
        "    (\"Ethanol\", \"CCO\"),\n",
        "    (\"Glucose\", \"C(C1C(C(C(C(O1)O)O)O)O)O\"),\n",
        "    (\"Acetic Acid\", \"CC(=O)O\"),\n",
        "    (\"Penicillin\", \"CC1(C(N2C(S1)C(C2=O)NC(=O)CC3=CC=CC=C3)C(=O)O)C\"),\n",
        "    (\"Naproxen\", \"CC(C1=CC=CC=C1)C(C2=CC=C(C=C2)C(=O)O)C(=O)O\")\n",
        "]\n",
        "\n",
        "# Prepare lists to store data for DataFrame\n",
        "common_names, smiles_list, encoded_selfies_list, decoded_smiles_list = [], [], [], []\n",
        "\n",
        "# Process each molecule\n",
        "for common_name, smiles in molecules:\n",
        "    common_names.append(common_name)\n",
        "    smiles_list.append(smiles)\n",
        "\n",
        "    # SMILES --> SELFIES translation\n",
        "    encoded_selfies = sf.encoder(smiles)\n",
        "    encoded_selfies_list.append(encoded_selfies)\n",
        "\n",
        "    # SELFIES --> SMILES translation\n",
        "    decoded_smiles = sf.decoder(encoded_selfies)\n",
        "    decoded_smiles_list.append(decoded_smiles)\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    \"Common Name\": common_names,\n",
        "    \"SMILES\": smiles_list,\n",
        "    \"Encoded SELFIES\": encoded_selfies_list,\n",
        "    \"Decoded SMILES\": decoded_smiles_list\n",
        "})\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "df.head(9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77EspbMLPPAU"
      },
      "outputs": [],
      "source": [
        "# Retrieve the list of robust alphabets from SELFIES\n",
        "robust_alphabets = list(sf.get_semantic_robust_alphabet())\n",
        "\n",
        "# Creating a DataFrame for the robust alphabets\n",
        "df = pd.DataFrame(robust_alphabets, columns=['Robust Alphabets'])\n",
        "\n",
        "# Print the number of characters and the DataFrame\n",
        "print(f\"Number of Characters in Robust Alphabets: {len(robust_alphabets)}\")\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', 70)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MPmJCBJPXgm"
      },
      "outputs": [],
      "source": [
        "# A subset of SELFIE alphabets\n",
        "alphabet_random = ['[=O]', '[O]', '[Ring2]', '[#Branch2]', '[#Branch3]'\n",
        "            '[N]', '[=Ring3]', '[#B]', '[H]',\n",
        "            '[#P]', '[Cl]', '[F]', '[Ring1]', '[P]', '[=Branch2]',\n",
        "            '[Br]', '[=S]', '[=N]', '[#N]', '[S]',\n",
        "            '[C]', '[I]', '[Ring3]', '[=C]', '[#C]'] + ['[C][=C][C][=C][C][=C][Ring1][=Branch1]'] * 10\n",
        "\n",
        "\n",
        "def get_random_molecule_using_selfies(num_random, robust_alphabets):\n",
        "    max_smi_len = 25\n",
        "    min_smi_len = 5\n",
        "    collect_random = []\n",
        "\n",
        "    for _ in range(num_random):\n",
        "        random_len = random.randint(min_smi_len, max_smi_len+1)\n",
        "        random_alphabets = list(np.random.choice(alphabet_random, random_len))\n",
        "        random_selfies = ''.join(x for x in random_alphabets)\n",
        "\n",
        "        collect_random.append(sf.decoder(random_selfies))\n",
        "\n",
        "    return [x for x in collect_random if x != '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEm5UBkfPano"
      },
      "outputs": [],
      "source": [
        "random_smiles = get_random_molecule_using_selfies(8, alphabet_random)\n",
        "\n",
        "mols = [Chem.MolFromSmiles(smi) for smi in random_smiles]\n",
        "img = Draw.MolsToGridImage(mols[:8], molsPerRow=4, subImgSize=(500, 500), legends=random_smiles)\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToUwUc5kPfJ-"
      },
      "source": [
        "> While some of these molecules may contain unresonable connections between functional groups, they are all **valid** molecules.\n",
        "\n",
        "### **Using SELFIES to explore analogous of Acetaminophen**\n",
        "By using a variation of the  ``` def get_random_molecule_using_selfies  ``` function, let's explore variations of Acetaminophen.\n",
        "\n",
        "```\n",
        "def get_random_molecule_using_selfies(num_random, robust_alphabets):\n",
        "    max_smi_len = 25\n",
        "    min_smi_len = 2\n",
        "    collect_random = []\n",
        "    \n",
        "    for _ in range(num_random):\n",
        "        random_len = random.randint(min_smi_len, max_smi_len+1)\n",
        "        random_alphabets = list(np.random.choice(alphabet, random_len))\n",
        "        random_selfies = ''.join(x for x in random_alphabets)\n",
        "        \n",
        "        collect_random.append(sf.decoder(random_selfies))\n",
        "    \n",
        "    return [x for x in collect_random if x != '']\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwDLb0VNPmTa"
      },
      "outputs": [],
      "source": [
        "acetaminophen_alphabet = ['[=O]', '[O]', '[Ring2]', '[#Branch2]', '[#Branch3]',\n",
        "                          '[N]', '[=Ring3]', '[Ring1]', '[P]', '[H]', '[#Branch1]'\n",
        "                          '[Br]', '[=S]', '[=N]', '[#N]', '[S]', '[=Ring2]', '[=Branch1]',\n",
        "                          '[C]', '[Ring3]', '[=C]', '[#C]' , '[#C+1]' , '[=N+1]']\n",
        "\n",
        "acetaminophen_smiles = 'CC(=O)Nc1ccc(cc1)O'\n",
        "\n",
        "def get_random_acetaminophen(num_random):\n",
        "    max_extra_len = 25\n",
        "    min_extra_len = 3\n",
        "    collect_random = []\n",
        "\n",
        "    for _ in range(num_random):\n",
        "        random_len = random.randint(min_extra_len, max_extra_len)\n",
        "        random_alphabets = list(np.random.choice(acetaminophen_alphabet, random_len))\n",
        "        random_selfies = ''.join(random_alphabets)\n",
        "\n",
        "        # Encoding acetaminophen_smiles and appending random_selfies\n",
        "        encoded_smiles = sf.encoder(acetaminophen_smiles) + random_selfies\n",
        "        decoded_smiles = sf.decoder(encoded_smiles)\n",
        "        if decoded_smiles is not None or decoded_smiles:\n",
        "            collect_random.append(decoded_smiles)\n",
        "\n",
        "    return collect_random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YEtDKQaPoZX"
      },
      "outputs": [],
      "source": [
        "random_acetaminophen = get_random_acetaminophen(8)\n",
        "\n",
        "ace_mols = [Chem.MolFromSmiles(ace_smi) for ace_smi in random_acetaminophen]\n",
        "img = Draw.MolsToGridImage(ace_mols[:8], molsPerRow=4, subImgSize=(500, 500), legends=random_acetaminophen)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ4aF6PSPqDb"
      },
      "outputs": [],
      "source": [
        "mols = []\n",
        "highlights = []\n",
        "acetaminophen_mol = Chem.MolFromSmiles(acetaminophen_smiles)\n",
        "\n",
        "for ace_smi in random_acetaminophen:\n",
        "    mol = Chem.MolFromSmiles(ace_smi)\n",
        "    mols.append(mol)\n",
        "    # Find the substructure\n",
        "    if mol.HasSubstructMatch(acetaminophen_mol):\n",
        "        substruct = mol.GetSubstructMatch(acetaminophen_mol)\n",
        "        highlights.append(substruct)\n",
        "    else:\n",
        "        highlights.append([])\n",
        "\n",
        "# Draw the molecules with highlighted substructure\n",
        "img = Draw.MolsToGridImage(mols, molsPerRow=4, subImgSize=(400, 400), highlightAtomLists=highlights)\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkHXyStSPsac"
      },
      "source": [
        "### **One-Hot Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgSaod-bPtO7"
      },
      "outputs": [],
      "source": [
        "# Encode molecules to SELFIES\n",
        "encoded_one_hot_random = [sf.encoder(molecule) for molecule in random_acetaminophen]\n",
        "\n",
        "# Determine the alphabet from the encoded molecules, include padding symbol\n",
        "molecule_alphabet_random = sf.get_alphabet_from_selfies(encoded_one_hot_random)\n",
        "molecule_alphabet_random.add('[nop]')\n",
        "molecule_alphabet_random = list(sorted(molecule_alphabet_random))\n",
        "\n",
        "# Calculate maximum length for padding\n",
        "max_length = max(sf.len_selfies(s) for s in encoded_one_hot_random)\n",
        "\n",
        "# Mapping from symbols to indices\n",
        "symbol_to_index_random = {s: i for i, s in enumerate(molecule_alphabet_random)}\n",
        "\n",
        "# Mapping from indices to symbols (reverse of symbol_to_index)\n",
        "vocab_itos_random = {i: s for s, i in symbol_to_index_random.items()}\n",
        "\n",
        "# Convert molecules to label-encoded and one-hot encoded formats\n",
        "encoded_data = []\n",
        "for molecule in encoded_one_hot_random:\n",
        "    label_encoded = sf.selfies_to_encoding(molecule,\n",
        "                                           vocab_stoi=symbol_to_index_random,\n",
        "                                           pad_to_len=max_length,\n",
        "                                           enc_type='label')\n",
        "    one_hot_encoded = sf.selfies_to_encoding(molecule,\n",
        "                                             vocab_stoi=symbol_to_index_random,\n",
        "                                             pad_to_len=max_length,\n",
        "                                             enc_type='one_hot')\n",
        "    encoded_data.append((molecule, label_encoded, one_hot_encoded))\n",
        "\n",
        "# Create DataFrame\n",
        "df_encoded_one_hot_random = pd.DataFrame(encoded_data, columns=['Molecule SELFIES', 'Label Encoded', 'One-Hot Encoded'])\n",
        "\n",
        "df_encoded_one_hot_random.head(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kruZDvM6QSmP"
      },
      "outputs": [],
      "source": [
        "print(vocab_itos_random)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRiwrh9FQViN"
      },
      "outputs": [],
      "source": [
        "# Choose the first one-hot encoded molecule for visualization\n",
        "one_hot_encoded_data = [data[2] for data in encoded_data]  # Replace '2' with the correct index for one-hot encoded data\n",
        "first_molecule_one_hot = one_hot_encoded_data[0]  # Select the first molecule\n",
        "\n",
        "# Create a list of symbols ordered by the index\n",
        "ordered_symbols = [vocab_itos_random[i] for i in range(len(vocab_itos_random))]\n",
        "\n",
        "\n",
        "# Enhanced plotting\n",
        "plt.figure(figsize=(13, 8))\n",
        "sns.set(font_scale=1.2)  # Increase font scale\n",
        "heatmap = sns.heatmap(first_molecule_one_hot, cmap=\"viridis\", cbar=True, linewidths= 1)\n",
        "heatmap.set_xticks(np.arange(len(ordered_symbols)) + 0.5)\n",
        "heatmap.set_xticklabels(ordered_symbols, rotation=90)\n",
        "heatmap.set_xlabel(\"Symbols in Vocab\", fontsize=14)\n",
        "heatmap.set_ylabel(\"Position in Molecule\", fontsize=14)\n",
        "heatmap.set_title(\"One-Hot Encoding of First Molecule\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSA8pOoNQn5Q"
      },
      "outputs": [],
      "source": [
        "# Select two random one-hot encoded molecules\n",
        "selected_indices = random.sample(range(len(encoded_data)), 2)\n",
        "selected_molecules = [encoded_data[i][2] for i in selected_indices]  # One-hot encoded\n",
        "\n",
        "# Decode and filter '[nop]'\n",
        "decoded_selfies = []\n",
        "for one_hot in selected_molecules:\n",
        "    decoded = sf.encoding_to_selfies(one_hot, vocab_itos_random, enc_type=\"one_hot\")\n",
        "    filtered_selfies = decoded.replace('[nop]', '')  # Remove '[nop]'\n",
        "    decoded_selfies.append(filtered_selfies)\n",
        "\n",
        "# Optionally convert to SMILES\n",
        "decoded_smiles = [sf.decoder(s) for s in decoded_selfies]\n",
        "\n",
        "# Displaying the decoded and filtered molecules\n",
        "for idx, (selfies, smiles) in enumerate(zip(decoded_selfies, decoded_smiles)):\n",
        "    print(f\"Molecule {idx + 1}:\")\n",
        "    print(\"SELFIES:\", selfies)\n",
        "    print(\"SMILES:\", smiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV0YYy-tOUiB"
      },
      "source": [
        "# **Classification of molecules using CNN**\n",
        "\n",
        "**Goals**\n",
        "1. Introduction to SMILES as molecular representation for ML models.\n",
        "2. Use ML models, more specifically **Convolutional NeuralNetworks** to classify molecules.\n",
        "\n",
        "\n",
        "\n",
        "## **Data loading and analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEU_5mJ68HRX"
      },
      "source": [
        "The Tox21 dataset from MoleculeNet is another baseline to test our model [37]. It contains the activities of 7,831 compounds against 12 biological targets or pathways, which are nuclear receptor(NR)-androgen receptor (AR)-ligand-binding domain (LBD), NR-AR, NR-aryl hydrocarbon receptor (AhR), NR-Aromatase, NR-estrogen receptor (ER)-LBD, NR-peroxisome proliferator-activated receptor (PPAR)-gamma, SR-antioxidant response element (ARE), stress response (SR)-ATPase Family AAA Domain Containing 5 (ATAD5), SR-heat shock factor response element (HSE), SR-mitochondrial membrane potential (MMP), and SR-p53 [38]. Similar to the CYP450 dataset, Tox21 includes many missing labels. We formulate the chemical toxicity prediction using the Tox21 dataset as a multi-label classification problem. The label for the target is positive if the chemical compound has toxicity by interacting with the target. The multi-label means one chemical compound can have more than one targets.\n",
        "\n",
        "Text from the [link](https://bio-protocol.org/exchange/minidetail?type=30&id=12688188)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFrO-C51Ods7"
      },
      "outputs": [],
      "source": [
        "data_url = \"https://github.com/RodrigoAVargasHdz/CHEM-4PB3/raw/w2024/Course_Notes/data/tox21.csv\"\n",
        "data_full = pd.read_csv(data_url)\n",
        "print('Total data:', data_full.count())\n",
        "data_full.head()\n",
        "data_full = data_full[['smiles','NR-AR']]\n",
        "\n",
        "print('Possible values of NR-AR:', data_full['NR-AR'].unique())\n",
        "\n",
        "data = data_full.dropna()\n",
        "data['NR-AR'] = data['NR-AR'].astype(int)\n",
        "\n",
        "print('Possible values of NR-AR:', data['NR-AR'].unique())\n",
        "print(data.head())\n",
        "data.hist(column='NR-AR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXNkfOPfOf77"
      },
      "source": [
        "> Plot some molecules that are not **HIV active**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPtrUoTFOlDZ"
      },
      "outputs": [],
      "source": [
        "PandasTools.AddMoleculeColumnToFrame(data, 'smiles')\n",
        "HIV_active_0 = data[data['NR-AR'] == 0]\n",
        "HIV_active_0_16 = PandasTools.FrameToGridImage(HIV_active_0[:9], column='ROMol', legendsCol='smiles',\n",
        "                                               molsPerRow=3, subImgSize=(300, 300))\n",
        "HIV_active_0_16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypXGCWZOOn8n"
      },
      "outputs": [],
      "source": [
        "PandasTools.AddMoleculeColumnToFrame(data, 'smiles')\n",
        "HIV_active_0 = data[data['NR-AR'] == 1]\n",
        "HIV_active_0_16 = PandasTools.FrameToGridImage(HIV_active_0[:9], column='ROMol', legendsCol='smiles',\n",
        "                                               molsPerRow=3, subImgSize=(300, 300))\n",
        "HIV_active_0_16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6ELQBc1Oqsl"
      },
      "source": [
        "From the previous class, we saw that a molecule written in the SMILES notation can be transformed into a *\"figure\"* using a dictionary of characters and the one-hot encoding transformation. <br>\n",
        "\n",
        "To create this dictionary, we first need to defined the maximum number of characters in a SMILE, meaning the length of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZLYJrUgQ88e"
      },
      "outputs": [],
      "source": [
        "data_negative = data[data['NR-AR'] == 0]\n",
        "data_positive = data[data['NR-AR'] == 1]\n",
        "\n",
        "# balanced dataset\n",
        "data_positive_d = pd.concat([data_positive, data_positive], axis=0)\n",
        "n_positive = len(data_positive_d)\n",
        "data_negative_red = data_negative.sample(n_positive)\n",
        "\n",
        "balanced_data = pd.concat([data_negative_red, data_positive_d], axis=0)\n",
        "balanced_data.head()\n",
        "print(balanced_data.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AilKVvgHmyQq"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8XbkzbcNPHY"
      },
      "outputs": [],
      "source": [
        "# Assuming 'balanced_data' is your DataFrame with a 'smiles' column\n",
        "global_alphabet_set = set()\n",
        "\n",
        "for si in balanced_data['smiles'].to_list():\n",
        "    # Encode SMILES to SELFIES\n",
        "    slfi = sf.encoder(si)\n",
        "\n",
        "    # Directly iterate over symbols in the SELFIES string\n",
        "    for symbol in sf.split_selfies(slfi):\n",
        "        # Add the symbol to the set if not already present\n",
        "        global_alphabet_set.add(symbol)\n",
        "\n",
        "    # Handling specific cases like radicals if needed\n",
        "    # if '[atom].' in slfi:\n",
        "    #     global_alphabet_set.add('[atom].')  # Or however you'd like to represent it\n",
        "\n",
        "# Optionally, convert the set back to a list and sort it\n",
        "global_alphabet_list = sorted(list(global_alphabet_set))\n",
        "\n",
        "\n",
        "if '.' not in global_alphabet_list:\n",
        "    global_alphabet_list.append('.')\n",
        "\n",
        "if '[nop]' not in global_alphabet_list:\n",
        "    global_alphabet_list.append('[nop]')\n",
        "\n",
        "global_alphabet = global_alphabet_list\n",
        "\n",
        "\n",
        "\n",
        "# Creating a DataFrame for the robust alphabets\n",
        "df = pd.DataFrame(global_alphabet, columns=['SELFIES'])\n",
        "\n",
        "# Print the number of characters and the DataFrame\n",
        "print(f\"Number of Characters in Global Alphabet: {len(global_alphabet)}\")\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', 70)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZNCtTjqOss-"
      },
      "outputs": [],
      "source": [
        "# global_alphabet = ['[=O]', '[O]', '[Ring2]', '[#Branch2]', '[#Branch3]', '[=Ring1]', '[=Ring2]',\n",
        "#                      '[N]', '[=Ring3]', '[#B]', '[H]', '[#P]', '[Cl]', '[#Branch1]', '[As]',\n",
        "#                      '[F]', '[Ring1]', '[P]', '[=Branch2]', '[Br]', '[NH1]', '[=N-1]', '[NaH1]',\n",
        "#                      '[=S]', '[=N]', '[#N]', '[S]', '[C]', '[I]', '[=N+1]', '[Mn+1]', '[Cl-1]',\n",
        "#                      '[Ring3]', '[=C]', '[#C]', '[Ag]', '[Pt]', '[K]', '[PH1]', '[N+1]',\n",
        "#                      '[Rh]', '[Zn]', '[Hg]', '[Fe]', '[Te]', '[Ca]', '[Se]', '.', '[=P]',\n",
        "#                      '[Li]', '[Mg]', '[Ge]', '[Cu]', '[Mo]', '[Mn]', '[Si]', '[O-1]',\n",
        "#                      '[Ni]', '[W]', '[U]', '[Branch1]', '[Branch2]', '[=Branch1]','[C@]',\n",
        "#                    '[C@H1]','[C@@H1]','[C@@]', '[N-1]','[/C]','[\\\\C]','[NH1+1]', '[/N]',\n",
        "#                    '[/O]','[Sb]','[\\\\C@H1]','[\\\\N+1]','[Mn+2]','[AlH3]','[=Mo]','[/C@@H1]',\n",
        "#                    '[Sn]','[Ba+2]','[=S+1]','[Cu+2]','[Na]','[=Bi]','[Fe+2]','[B-1]','[B]',\n",
        "#                    '[Pd]','[Au-1]','[S-1]','[\\\\Cl]','[Zn+2]','[\\\\O]','[K+1]','[Br-1]','[In]',\n",
        "#                    '[\\\\S]','[Na+1]','[SbH6+3]', '[SiH1]', '[\\\\N]',  '[N@@+1]', '[I-1]', '[Hg+2]',\n",
        "#                    '[PbH2+2]','[Fe+3]','[Fe-1]','[NH3+1]','[Bi]','[=Se]','[NH4+1]','[Co+2]',\n",
        "#                    '[/C@H1]','[P+1]','[S+1]','[Cr+2]','[CH1-1]','[Dy]','[Ni+2]','[TlH2+1]',\n",
        "#                    '[nop]']\n",
        "\n",
        "\n",
        "\n",
        "def smiles_to_one_hot_and_list(smile, max_length, alphabet=global_alphabet):\n",
        "    \"\"\"\n",
        "    Converts a SMILES string to a one-hot encoded matrix and a list of SELFIES symbols.\n",
        "    \"\"\"\n",
        "    selfies_str = sf.encoder(smile)\n",
        "\n",
        "    molecule_alphabet = sorted(alphabet)\n",
        "\n",
        "    symbol_to_index = {s: i for i, s in enumerate(molecule_alphabet)}\n",
        "    vocab_itos = {i: s for s, i in symbol_to_index.items()}\n",
        "    one_hot_encoded = sf.selfies_to_encoding(selfies_str,\n",
        "                                             vocab_stoi=symbol_to_index,\n",
        "                                             pad_to_len=max_length,\n",
        "                                             enc_type='one_hot')\n",
        "\n",
        "    selfies_list = selfies_str.split('][')\n",
        "    selfies_list[0] = selfies_list[0][1:]\n",
        "    selfies_list[-1] = selfies_list[-1][:-1]\n",
        "    selfies_output_list = ['[' + selfie + ']' for selfie in selfies_list]\n",
        "    one_hot_encoded = np.array(one_hot_encoded).T\n",
        "    # Padding\n",
        "    if one_hot_encoded.shape[0] < max_length:\n",
        "        padding = np.zeros((max_length - one_hot_encoded.shape[0], one_hot_encoded.shape[1]))\n",
        "        one_hot_encoded = np.vstack((one_hot_encoded, padding))\n",
        "\n",
        "    return one_hot_encoded, symbol_to_index, vocab_itos, selfies_output_list\n",
        "\n",
        "# smile = 'CC(C)C(C(=O)O)n1[se]c2ccccc2c1=O'\n",
        "rnd_data = balanced_data.sample(1)\n",
        "smile = rnd_data['smiles'].item()\n",
        "print(smile)\n",
        "selfies_str = sf.encoder(smile)\n",
        "\n",
        "max_l = sf.len_selfies(selfies_str) + 10\n",
        "\n",
        "one_hot_encoded, symbol_to_index, vocab_itos, selfies_tokens = smiles_to_one_hot_and_list(smile, max_l)\n",
        "\n",
        "print('SELFIES image:', one_hot_encoded.shape)\n",
        "\n",
        "print(symbol_to_index)\n",
        "print(vocab_itos)\n",
        "print(selfies_tokens)\n",
        "\n",
        "mol = AllChem.MolFromSmiles(smile)\n",
        "# mol\n",
        "\n",
        "img=Draw.MolsToGridImage([mol,mol],molsPerRow=2,subImgSize=(500,500),legends=[smile,selfies_str])\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b8ju3_eOu-5"
      },
      "outputs": [],
      "source": [
        "# Create a list of symbols ordered by the index in vocab_itos\n",
        "ordered_symbols = [vocab_itos[i] for i in range(len(vocab_itos))]\n",
        "\n",
        "plt.figure(figsize=(19, 10))\n",
        "sns.set(font_scale=1.2)  # Increase font scale\n",
        "heatmap = sns.heatmap(one_hot_encoded, cmap=\"viridis\", cbar=True, linewidths=1,\n",
        "                      yticklabels=ordered_symbols, xticklabels=selfies_tokens)  # y-axis: ordered_symbols, x-axis: selfies_tokens\n",
        "\n",
        "# Adjusting ticks and labels\n",
        "#heatmap.set_xticks(np.arange(len(selfies_tokens)))  # Set x-ticks for selfies_tokens\n",
        "heatmap.set_xticklabels(selfies_tokens, rotation=90, fontsize=8)  # Set x-tick labels with font size\n",
        "heatmap.set_yticks(np.arange(len(ordered_symbols)))  # Set y-ticks for ordered_symbols\n",
        "heatmap.set_yticklabels(ordered_symbols, fontsize=8)  # Set y-tick labels with font size\n",
        "\n",
        "heatmap.set_xlabel(\"SELFIES Tokens\", fontsize=14)\n",
        "heatmap.set_ylabel(\"Symbols in Vocab\", fontsize=14)\n",
        "heatmap.set_title(\"One-Hot Encoding of Molecules\", fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cztv4HgSYtDE"
      },
      "source": [
        "Let's create a Data loader for this dataset.\n",
        "1. We will transform each smile into its \"figure\" representation\n",
        "2. Because we are working with two-classes, 'active' and 'inactive'. We also need to transform the label/class to one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMGXms9UeI1A"
      },
      "outputs": [],
      "source": [
        "max_length = 0\n",
        "for smile in balanced_data['smiles']:\n",
        "    try:\n",
        "        selfies_str = sf.encoder(smile)  # Convert to SELFIES\n",
        "        length_selfies = sf.len_selfies(selfies_str)\n",
        "        if length_selfies > max_length:\n",
        "            max_length = length_selfies\n",
        "    except sf.EncoderError:\n",
        "        print(f\"Skipping SMILES string due to encoding error: {smile}\")\n",
        "\n",
        "print('Max SELFIES length', max_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btCr3e4Dx96n"
      },
      "outputs": [],
      "source": [
        "# torch new data loader\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, smiles_all, labels_all, max_length, global_alphabet):\n",
        "        self.labels = labels_all\n",
        "        self.smiles = smiles_all\n",
        "        self.max_length = max_length\n",
        "        self.global_alphabet = global_alphabet\n",
        "        self.symbol_to_index = {s: i for i, s in enumerate(sorted(self.global_alphabet))}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        si = self.smiles[idx]\n",
        "        labels = self.labels[idx]\n",
        "        mi, _, _, _ = smiles_to_one_hot_and_list(si, self.max_length, self.global_alphabet)\n",
        "        molecules_torch = torch.from_numpy(mi).float()\n",
        "        labels_one_hot = F.one_hot(torch.tensor(labels), num_classes=2)\n",
        "\n",
        "        return molecules_torch.unsqueeze(0), labels_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM2O05_faT7y"
      },
      "outputs": [],
      "source": [
        "data_full = balanced_data\n",
        "train_size = int(0.8 * len(data_full))  # 80% for training\n",
        "validation_size = len(data_full) - train_size  # 20% for validation\n",
        "print('Training data', train_size)\n",
        "print('Test data', validation_size)\n",
        "# train_dataset, validation_dataset = random_split(\n",
        "#     data_full, [train_size, validation_size])\n",
        "tr_dataset = data_full.sample(train_size)\n",
        "val_dataset = data_full.sample(validation_size)\n",
        "\n",
        "\n",
        "training_data = CustomDataset(\n",
        "    tr_dataset['smiles'].to_list(), tr_dataset['NR-AR'].to_list(), max_length, global_alphabet)\n",
        "train_dataloader = DataLoader(training_data, batch_size=512, shuffle=True)\n",
        "train_molecules, train_labels = next(iter(train_dataloader))\n",
        "\n",
        "print('Size of the training data')\n",
        "print(train_molecules.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P_K8W91fRkH"
      },
      "source": [
        "## CNN ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu5w6r-zfTVH"
      },
      "outputs": [],
      "source": [
        "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, 5,padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(6, 16, 5,padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )        # fully connected layer, output 10 classes\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(16 * 59 * 59, 512),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "        self.fc3 = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        # print(x.shape)\n",
        "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "        x = self.conv2(x)\n",
        "        # print(x.shape)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        # print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.fc2(x)\n",
        "        # print(x.shape)\n",
        "        output = self.fc3(x)\n",
        "        return output   # return x for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tHCTuDHfVuv"
      },
      "outputs": [],
      "source": [
        "def train(model, training_data, training_epochs=60,device='cuda'):\n",
        "    # Define the loss function and optimizer\n",
        "    model.train()\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        training_data, batch_size=64, shuffle=True)\n",
        "\n",
        "    iterator = tqdm.notebook.tqdm(range(training_epochs))\n",
        "\n",
        "    # Run the training loop (epochs)\n",
        "    loss_trajectory = []\n",
        "    for epoch in iterator:\n",
        "\n",
        "        # Set current loss value\n",
        "        current_loss = []\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, targets = data\n",
        "            inputs, targets = inputs.to(device), targets.to(device) # move data to GPU\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_function(outputs, targets.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print statistics\n",
        "            # current_loss += loss.item()\n",
        "            current_loss.append(loss.item())\n",
        "        # scheduler.step()\n",
        "        # print('Epoch %s: %.4f +- %.4f'%(epoch,np.array(current_loss).mean(),np.array(current_loss).std()))\n",
        "        iterator.set_postfix(loss=torch.tensor(current_loss).mean())\n",
        "        loss_trajectory.append(current_loss)\n",
        "        # Process is complete.\n",
        "    return loss_trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOyQv_XPIG2T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"TorchVision version: {torchvision.__version__}\")\n",
        "\n",
        "# Set the target device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device = 'cpu'\n",
        "\n",
        "# print(f\"Using device: {device}\")\n",
        "# total_free_gpu_memory, total_gpu_memory = torch.cuda.mem_get_info()\n",
        "# print(f\"Total free GPU memory: {round(total_free_gpu_memory * 1e-9, 3)} GB\")\n",
        "# print(f\"Total GPU memory: {round(total_gpu_memory * 1e-9, 3)} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N730cYXjsrIv"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "cnn.to(device)\n",
        "compiled_cnn = torch.compile(cnn) # new!\n",
        "print(train_molecules.shape)\n",
        "# labels = cnn(train_molecules)\n",
        "# print(labels)\n",
        "\n",
        "# loss_trj = train(cnn, training_data,100,device)\n",
        "# # Specify a path\n",
        "# PATH = 'checkpoint.pth' #name of the file\n",
        "\n",
        "# # Save\n",
        "# torch.save(cnn.state_dict(), 'checkpoint.pth')\n",
        "\n",
        "# loss_trj = np.array(loss_trj)\n",
        "# m = np.mean(loss_trj,axis=1)\n",
        "# std = np.std(loss_trj,axis=1)\n",
        "\n",
        "# plt.errorbar(np.arange(m.shape[0]), m, yerr=std, errorevery=(0, 6))\n",
        "# plt.xlabel('Iterations')\n",
        "# plt.ylabel('Error')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtvZziU9JzB-"
      },
      "source": [
        "## Save and Load modules ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQZVOQ5kqzXS"
      },
      "outputs": [],
      "source": [
        "!ls\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFV6OLmnJ76W"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "model_new = CNN()\n",
        "PATH = \"/content/checkpoint.pth\"\n",
        "# model_new.load_state_dict(torch.load(PATH))\n",
        "\n",
        "\n",
        "state_dict = torch.load(PATH)\n",
        "model_new.load_state_dict(state_dict)\n",
        "\n",
        "model_new.eval()\n",
        "labels = model_new(train_molecules)\n",
        "print(labels)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCQIwnsEJ2aQ"
      },
      "source": [
        "# Prediction #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1E5cquEMplq"
      },
      "outputs": [],
      "source": [
        "val_data = CustomDataset(\n",
        "    val_dataset['smiles'].to_list(), val_dataset['NR-AR'].to_list(), max_length, global_alphabet)\n",
        "val_dataloader = DataLoader(val_data , batch_size=len(val_dataset), shuffle=True)\n",
        "\n",
        "val_molecules, val_labels = next(iter(val_dataloader))\n",
        "val_molecules, val_labels = val_molecules.to(device), val_labels.to(device)\n",
        "\n",
        "cnn.eval()\n",
        "val_labels_pred = cnn(val_molecules)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "loss = loss_function(val_labels_pred, val_labels.float())\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU7S0tzEv4Ra"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "# Calculate F1 score\n",
        "\n",
        "actual_labels = val_labels.detach().cpu().numpy()\n",
        "actual_labels = np.argmax(actual_labels,axis=1)\n",
        "predictions = val_labels_pred.softmax(axis=1).detach().cpu().numpy()\n",
        "predictions = np.argmax(predictions,axis=1)\n",
        "\n",
        "f1 = f1_score(actual_labels, predictions, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "i0 = np.where(np.abs(predictions - actual_labels) >0 )[0]\n",
        "print('Total data:', actual_labels.shape[0])\n",
        "print('% of missclassified data', 100*(i0.shape[0]/actual_labels.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psHHw0SJy-SH"
      },
      "outputs": [],
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(actual_labels, predictions)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a06LVD0ZiDu"
      },
      "source": [
        "# Plot the filters #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcREQ8PbabKB"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_filter(filter_params):\n",
        "  f_min, f_max = filter_params.min(), filter_params.max()\n",
        "  filters = (filter_params - f_min) / (f_max - f_min)\n",
        "\n",
        "  num_filters,n_in_ch,fltr_x,fltr_y = filters.shape\n",
        "  print(filters.shape)\n",
        "\n",
        "  num_columns = n_in_ch\n",
        "  # num_rows = np.ceil(num_filters / num_columns).astype(int)\n",
        "  num_rows = np.ceil((num_filters*n_in_ch) / num_columns).astype(int)\n",
        "  fig, axes = plt.subplots(num_rows, num_columns, figsize=(n_in_ch*1.5, num_filters*1.5))\n",
        "  axes = axes.flatten()\n",
        "\n",
        "  ix = 0\n",
        "  for i in range(num_filters):\n",
        "    for j in range(n_in_ch):\n",
        "      # For each filter, plot its weights\n",
        "        img = np.squeeze(filters[i,j])\n",
        "\n",
        "        ax = axes[ix]\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.axis('off')\n",
        "        ix += 1\n",
        "\n",
        "  # Adjust layout\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts1UwTcwZjaR"
      },
      "outputs": [],
      "source": [
        "for name, param in cnn.named_parameters():\n",
        "    # print(name, param.size())\n",
        "    if 'conv' in name and 'weight' in name:\n",
        "      print(name,param.size())\n",
        "      plot_filter(param.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTDEr5kv3Ez8"
      },
      "source": [
        "# Motifs #\n",
        "**Paper:** Convolutional neural network based on SMILES representation of compounds for detecting chemical motif\n",
        "[link](https://doi.org/10.1186/s12859-018-2523-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoWPVrxM3Vyr"
      },
      "outputs": [],
      "source": [
        "from torch import nn, Tensor\n",
        "\n",
        "class VerboseExecution(nn.Module):\n",
        "    def __init__(self, model: nn.Module):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "        # Register a hook for each layer\n",
        "        for name, layer in self.model.named_children():\n",
        "            layer.__name__ = name\n",
        "            layer.register_forward_hook(\n",
        "                lambda layer, _, output: print(f\"{layer.__name__}: {output.shape}\")\n",
        "            )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjVSy7pG3NQO"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Iterable, Callable\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, model: nn.Module, layers: Iterable[str]):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.layers = layers\n",
        "        self._features = {layer: torch.empty(0) for layer in layers}\n",
        "\n",
        "        for layer_id in layers:\n",
        "            layer = dict([*self.model.named_modules()])[layer_id]\n",
        "            layer.register_forward_hook(self.save_outputs_hook(layer_id))\n",
        "\n",
        "    def save_outputs_hook(self, layer_id: str) -> Callable:\n",
        "        def fn(_, __, output):\n",
        "            self._features[layer_id] = output\n",
        "        return fn\n",
        "\n",
        "    def forward(self, x: Tensor) -> Dict[str, Tensor]:\n",
        "        _ = self.model(x)\n",
        "        return self._features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk3VK1uB3ZkH"
      },
      "outputs": [],
      "source": [
        "full_data = CustomDataset(\n",
        "    data_full['smiles'].to_list(), data_full['NR-AR'].to_list(), max_length, global_alphabet)\n",
        "full_dataloader = DataLoader(full_data, batch_size=1240, shuffle=False)\n",
        "print(len(data_full))\n",
        "print(len(full_data))\n",
        "\n",
        "molecules, labels = next(iter(full_dataloader))\n",
        "molecules, labels = molecules.to(device), labels.to(device)\n",
        "print(molecules.shape,labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUntaAZ35DS2"
      },
      "outputs": [],
      "source": [
        "verbose_cnn = VerboseExecution(cnn)\n",
        "_ = verbose_cnn(molecules[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn4oH_uO9So2"
      },
      "source": [
        "In practice, each dimension of SCFP may have a\n",
        "different value scale, making it difficult to compare\n",
        "across dimensions for identifying large-contribution fil-\n",
        "ters. Thus, we normalize SCFP by the following proce-\n",
        "dure. First, we compute SCFP for all compounds in a\n",
        "given dataset. Then, we look at the values in the global\n",
        "max-pooling layer, and calculate their mean and variance\n",
        "for each filter over all compounds. Finally, we transform\n",
        "SCFP into Z-scores for each dimension by using the mean\n",
        "and the variance of the corresponding filter. For detect-\n",
        "ing chemical motifs, we focus on those dimensions of\n",
        "SCFP with Z-scores larger than 2.58 (i.e., 99% percentile).\n",
        "Note that this normalization procedure is only used\n",
        "for detecting chemical motifs, but not for training and\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpFWaAi9-WNz"
      },
      "outputs": [],
      "source": [
        "cnn_features = FeatureExtractor(cnn, layers=[\"conv2\"])\n",
        "z = cnn_features(molecules)\n",
        "z = torch.flatten(z['conv2'], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUfegaVS6VG4"
      },
      "outputs": [],
      "source": [
        "print(z.shape)\n",
        "#compute the mean and std for each filter\n",
        "mean_ = torch.mean(z,0,keepdim=False)\n",
        "std_ = torch.std(z,0,keepdim=False) + 1E-6\n",
        "print(mean_.shape,std_.shape)\n",
        "print(std_)\n",
        "\n",
        "z_score = torch.abs((z[:2,:] - mean_)/std_)\n",
        "print(z_score)\n",
        "\n",
        "max_zscore = torch.max(z_score,axis=0)[0].detach().cpu()\n",
        "\n",
        "plt.scatter(np.arange(max_zscore.shape[0]),max_zscore)\n",
        "plt.hlines(2.58,0,max_zscore.shape[0],color='k',ls='--')\n",
        "plt.xlabel('Filter number')\n",
        "plt.ylabel('Z score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-qf6FJx6kMU"
      },
      "outputs": [],
      "source": [
        "i0 = torch.where(max_zscore > 2.58,1.,0.)\n",
        "for jj0, j0 in enumerate(i0):\n",
        "  if j0 == 1.:\n",
        "    indx = int(torch.argmax(z_score[:,jj0]).detach().cpu())\n",
        "    print('best molecule',indx)\n",
        "    print('filter number', jj0)\n",
        "    print(data_full.iloc[indx])\n",
        "\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNLcHTo9ERMH"
      },
      "outputs": [],
      "source": [
        "si = 'CC(=O)OC/C=C(\\C)CC/C=C(\\C)CCC=C(C)C'\n",
        "data_i = CustomDataset([si],[0],max_length, global_alphabet)\n",
        "datai_loader = DataLoader(data_i)\n",
        "mi,_ = next(iter(datai_loader))\n",
        "print(mi.shape)\n",
        "zi = cnn_features(mi.to(device))\n",
        "zi = zi['conv2']\n",
        "# zi = torch.flatten(zi['conv2'], 1)\n",
        "print(zi.shape)\n",
        "\n",
        "# plt.imshow(zi[0,4].detach().cpu(),cmap='gray')\n",
        "num_filters = zi[0].shape[0]\n",
        "fig, axes = plt.subplots( 2,int(num_filters/2), figsize=(100, 100))\n",
        "axes = axes.flatten()\n",
        "\n",
        "ix = 0\n",
        "for i in range(num_filters):\n",
        "    # For each filter, plot its weights\n",
        "      img = np.squeeze(zi[0,i])\n",
        "\n",
        "      ax = axes[ix]\n",
        "      ax.imshow(img.detach().cpu(), cmap='gray')\n",
        "      ax.axis('off')\n",
        "      ix += 1\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PcdluD0GtMi"
      },
      "outputs": [],
      "source": [
        "selfies_str = sf.encoder(si)\n",
        "\n",
        "max_l = sf.len_selfies(selfies_str) + 10\n",
        "\n",
        "one_hot_encoded, symbol_to_index, vocab_itos, selfies_tokens = smiles_to_one_hot_and_list('CC(=O)OC/C=C(\\C)CC/C=C(\\C)CCC=C(C)C', max_l)\n",
        "\n",
        "# Create a list of symbols ordered by the index in vocab_itos\n",
        "ordered_symbols = [vocab_itos[i] for i in range(len(vocab_itos))]\n",
        "\n",
        "plt.figure(figsize=(19, 10))\n",
        "sns.set(font_scale=1.2)  # Increase font scale\n",
        "heatmap = sns.heatmap(one_hot_encoded, cmap=\"viridis\", cbar=True, linewidths=1,\n",
        "                      yticklabels=ordered_symbols, xticklabels=selfies_tokens)  # y-axis: ordered_symbols, x-axis: selfies_tokens\n",
        "\n",
        "# Adjusting ticks and labels\n",
        "#heatmap.set_xticks(np.arange(len(selfies_tokens)))  # Set x-ticks for selfies_tokens\n",
        "heatmap.set_xticklabels(selfies_tokens, rotation=90, fontsize=8)  # Set x-tick labels with font size\n",
        "heatmap.set_yticks(np.arange(len(ordered_symbols)))  # Set y-ticks for ordered_symbols\n",
        "heatmap.set_yticklabels(ordered_symbols, fontsize=8)  # Set y-tick labels with font size\n",
        "\n",
        "heatmap.set_xlabel(\"SELFIES Tokens\", fontsize=14)\n",
        "heatmap.set_ylabel(\"Symbols in Vocab\", fontsize=14)\n",
        "heatmap.set_title(\"One-Hot Encoding of Molecules\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9HcfmdIK-T8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
