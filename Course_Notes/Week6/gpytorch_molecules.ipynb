{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XVJee2rmJILE"
      },
      "source": [
        "To open on Google Colab\\\n",
        "https://colab.research.google.com/github/RodrigoAVargasHdz/CHEM-4PB3/blob/main/Course_Notes/Week6/gpytorch_molecules.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B876ATr-JMNJ",
        "outputId": "67880ada-c108-4e3b-d6c0-2c6747b7c5be"
      },
      "outputs": [],
      "source": [
        "!pip install gpytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X-2kzffJILK"
      },
      "source": [
        "## Data an original model\n",
        "Load data from the [paper](th.fhi-berlin.mpg.de/site/uploads/Publications/QM-NJP_20130315.pdf)\n",
        "\n",
        "model was first introduce in 2012\n",
        "[paper](https://www.mrupp.info/Data/2012rtmvl_prl.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCQAN5OmJILL",
        "outputId": "f37eafdd-f6d1-432e-b5cf-8162d4c35478"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#load data\n",
        "data_url = \"https://github.com/RodrigoAVargasHdz/CHEM-4PB3/raw/main/Course_Notes/data/qm7.csv\"\n",
        "data = pd.read_csv(data_url)\n",
        "# print(data.head)\n",
        "print(data.columns)\n",
        "\n",
        "Xtot = data.drop(['Unnamed: 0','AtomizationEnergy'], axis=1).to_numpy()\n",
        "ytot = data['AtomizationEnergy'].to_numpy()  # [:,np.newaxis]\n",
        "mu_data = np.mean(ytot)\n",
        "std_data = np.std(ytot)\n",
        "ytot = (ytot-mu_data)/std_data\n",
        "Ctot = Xtot.reshape(Xtot.shape[0],23,23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqins_JnJILN"
      },
      "source": [
        "From Eq. 2 in the [paper](https://www.mrupp.info/Data/2012rtmvl_prl.pdf), we see that the authors proposed the eigenvalues of the Coulomb matrix as the \n",
        "features of our model. \n",
        "1. $\\mathbf{\\epsilon}$ -> eigenvalues of the Coulomb matrix\n",
        "2. $C$ -> Coulomb matrix\n",
        "\n",
        "The elements of the C matrix are given by,\\\n",
        "$C_{ij} = \\Big\\{ \\begin{matrix} 0.5 Z_i^{2.4} \\;\\;\\;\\;\\text{if }\\;\\; i=j\\\\ \\frac{Z_iZ_j}{|R_i - R_j|} \\;\\;\\;\\;\\text{if }\\;\\; i\\neq j \\end{matrix}$,\n",
        "where,\n",
        "1. $R_{i}$ is the position of atom-i\n",
        "2. $Z_{i}$ is the atomic number of atom-i\n",
        "\n",
        "\n",
        "To compute the eigenvalues of C we can use numpy ``` np.linalg.eigh(C)```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "043KtkWKJILO"
      },
      "outputs": [],
      "source": [
        "Ctot_eig = []\n",
        "for c in Ctot:\n",
        "    e,_ = np.linalg.eigh(c)\n",
        "    Ctot_eig.append(e)\n",
        "\n",
        "Ctot_eig = np.array(Ctot_eig)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x1HU5K-TJILP"
      },
      "source": [
        "## Train a GP using GPyTorch\n",
        "The kernel function proposed in the [paper](https://www.mrupp.info/Data/2012rtmvl_prl.pdf) is, (below if Equation (3))\\\n",
        "$K_{ij}=\\exp^{-\\frac{d(\\mathbf{C}_i,\\mathbf{C}_j)}{2\\ell^2}}$,\\\n",
        "where,\\\n",
        "$d(\\mathbf{C}_i,\\mathbf{C}_j) = d(\\mathbf{\\epsilon}_i,\\mathbf{\\epsilon}_j) = \\sqrt{\\sum_\\kappa |\\epsilon^\\kappa_i - \\epsilon^\\kappa_j|^2}$,\\\n",
        "where,\n",
        "* $\\epsilon^\\kappa_i$ is the $\\kappa$-th eigenvalue of the C matrix from molecule-i.\n",
        "\n",
        "$d(\\mathbf{C}_i,\\mathbf{C}_j)$ is simply an isotropic RBF kernel (can you see it?)\n",
        "\n",
        "![Arrays](https://raw.github.com/RodrigoAVargasHdz/CHEM-4PB3/master/Course_Notes/Figures/kernel_PRL2012.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWnXovQBJILQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gpytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH1-JBskJILQ"
      },
      "outputs": [],
      "source": [
        "class ExactGPModel(gpytorch.models.ExactGP):\n",
        "    def __init__(self, train_x, train_y, likelihood):\n",
        "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean()\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
        "            gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[1]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0TIh2aZJILU"
      },
      "outputs": [],
      "source": [
        "# # data\n",
        "N = 2500\n",
        "Nval = 5000\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    Ctot_eig, ytot, test_size=ytot.shape[0] - N, random_state=0)\n",
        "if Nval > 0:\n",
        "    X_test, y_test = X_test[:Nval], y_test[:Nval]\n",
        "    Xtr, Xtst, ytr, ytst = X_train, X_test, y_train, y_test\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    Xtr = torch.from_numpy(Xtr).cuda()\n",
        "    ytr = torch.from_numpy(ytr).float().cuda()\n",
        "    Xtst = torch.from_numpy(Xtst).double().cuda()\n",
        "    ytst = torch.from_numpy(ytst).float().cuda()\n",
        "else:\n",
        "    Xtr = torch.from_numpy(Xtr)\n",
        "    ytr = torch.from_numpy(ytr).float()\n",
        "    Xtst = torch.from_numpy(Xtst).double()\n",
        "    ytst = torch.from_numpy(ytst).float()\n",
        "\n",
        "Xtot = torch.from_numpy(Ctot_eig)\n",
        "ytot = torch.from_numpy(ytot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0pufy0kJILW"
      },
      "source": [
        "### training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45x172tvJILW"
      },
      "outputs": [],
      "source": [
        "# initialize likelihood and model\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood().double()\n",
        "likelihood.noise = 1e-4  # Some small value, but don't make it too small or numerical performance will suffer. I recommend 1e-4.\n",
        "likelihood.noise_covar.raw_noise.requires_grad_(False)\n",
        "model = ExactGPModel(Xtr, ytr, likelihood).double()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    likelihood.cuda()\n",
        "    model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WYBmcXv7JILX",
        "outputId": "31a97647-2166-4892-9e0d-914486e63927"
      },
      "outputs": [],
      "source": [
        "# Find optimal model hyperparameters using ADAM\n",
        "\n",
        "# Use the adam optimizer\n",
        "# Includes GaussianLikelihood parameters\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.5)\n",
        "\n",
        "# \"Loss\" for GPs - the marginal log likelihood\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "training_iter = 500\n",
        "mll_trajectory = []\n",
        "mll_trajectory_tst = []\n",
        "for i in range(training_iter):\n",
        "    model.train()\n",
        "    likelihood.train()\n",
        "    # Zero gradients from previous iteration\n",
        "    optimizer.zero_grad()\n",
        "    # Output from model\n",
        "    output = model(Xtr)\n",
        "    # Calc loss and backprop gradients\n",
        "    loss = -mll(output, ytr)\n",
        "    loss.backward()\n",
        "    mll_trajectory.append(loss.item())\n",
        "\n",
        "    if (i % 10) == 0.:\n",
        "      print('Iter %d/%d - Loss: %.3f  noise: %.6f' % (\n",
        "          i, training_iter, loss.item(),\n",
        "          model.likelihood.noise.item()\n",
        "      ))\n",
        "      print('lengthscale: ', model.covar_module.base_kernel.lengthscale[0])\n",
        "    optimizer.step()\n",
        "    # with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
        "    #     model.eval()\n",
        "    #     likelihood.eval()\n",
        "    #     ypred = likelihood(model(Xtst))\n",
        "    #     mse = torch.sqrt(torch.sum((ypred.mean - ytst)**2))\n",
        "    #     mll_trajectory_tst.append(mse.cpu())\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKe95x7GMiA5"
      },
      "outputs": [],
      "source": [
        "# Prediction with GPyTorch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# \tIn all other cases, he suggests using a power of 2 as the mini-batch size.\n",
        "# \tSo the minibatch should be 64, 128, 256, 512, or 1024 elements large.\n",
        "\n",
        "dummy_test_y = torch.full_like(Xtst, dtype=torch.long, fill_value=0)\n",
        "test_dataset = TensorDataset(Xtst, dummy_test_y)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "means = torch.tensor([0.])\n",
        "stds = torch.tensor([[0.,0]])\n",
        "\n",
        "model.eval()\n",
        "likelihood.eval()\n",
        "with torch.no_grad():\n",
        "    for x_batch, _ in test_loader:\n",
        "      if torch.cuda.is_available():\n",
        "          xb = x_batch\n",
        "      else:\n",
        "          xb = x_batch#.cuda()\n",
        "      preds = likelihood(model(xb))\n",
        "      mean = preds.mean.cpu()\n",
        "      means = torch.cat([means, mean])\n",
        "      # l,u = preds.confidence_region()\n",
        "      # std = torch.column_stack((l,u))\n",
        "      # stds = torch.vstack((stds,std.cpu()))\n",
        "      # stds = torch.vstack(stds,std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "1byKL9fESPH0",
        "outputId": "7a831664-6933-4b66-fb51-2f5a7efa960f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "ytot_gp = means[1:].cpu().numpy() # torch to numpy \n",
        "ytst.cpu()\n",
        "r2 = r2_score(ytot_gp,ytst.cpu())\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(ytot_gp,ytst.cpu(),s=5)\n",
        "\n",
        "low = np.min(np.stack((ytot_gp,ytst.cpu())).flatten())\n",
        "high = np.max(np.stack((ytot_gp,ytst.cpu())).flatten())\n",
        "plt.plot([low, high], [low, high], ls=\"--\", c=\"red\",lw=2.)\n",
        "\n",
        "# plt.title('H3O+ PES (N=%s)'%N,fontsize=18)\n",
        "# plt.text(0.02,0.08,r'$R^{2}$ = %.3f'%r2,fontsize=18)\n",
        "# plt.xlabel('GP prediction',fontsize=18)\n",
        "# plt.ylabel('Quantum Chemistry',fontsize=18)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsPI-7Z7JILZ"
      },
      "source": [
        "# Single molecule test case after training a GP model with GPytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12VkT0ovJILa",
        "outputId": "472b4fd6-94d9-4ace-880d-cac6c7056720"
      },
      "outputs": [],
      "source": [
        "# CH4\n",
        "molec = '''\n",
        "C \t0.000 \t0.000 \t0.000\n",
        "H \t0.634 \t0.634 \t0.634\n",
        "H \t-0.634 \t-0.634 \t0.634\n",
        "H \t-0.634 \t0.634 \t-0.634\n",
        "H \t0.634 \t-0.634 \t-0.634\n",
        "'''\n",
        "molec = molec.split()\n",
        "molec = np.array(molec)\n",
        "molec = molec.reshape(5,4)\n",
        "print(molec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKvdqXiEJILb"
      },
      "outputs": [],
      "source": [
        "def get_atomic_number(atoms):\n",
        "    atomic_numbers = {'H':1.,'C':6,'O':8}\n",
        "    Z = []\n",
        "    for x in molec:\n",
        "        zi = atomic_numbers[x[0]]\n",
        "        Z.append(zi)\n",
        "    return np.array(Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcwQMytBJILc"
      },
      "outputs": [],
      "source": [
        "def get_Cmatrix(molec):\n",
        "    atoms = molec[:,0]\n",
        "    molec = molec[:,1:]\n",
        "    Zii = get_atomic_number(atoms)\n",
        "\n",
        "    XYZ = np.array(molec,dtype=np.float32)\n",
        "    diff =  XYZ[np.newaxis,:] - XYZ[:,np.newaxis]\n",
        "    R = np.linalg.norm(diff,axis=-1,ord=1)\n",
        "    Zij = Zii[:,np.newaxis] * Zii[np.newaxis,:]\n",
        "    Rdiag = np.eye(R.shape[0])\n",
        "    R = R + Rdiag\n",
        "    R_inv = 1./R\n",
        "    C = Zij * R_inv\n",
        "    \n",
        "    C_diag = 0.5*np.power(Zii, 2.4)\n",
        "    C[np.diag_indices(R.shape[0])] = C_diag\n",
        "    C_pad = np.zeros((23,23))\n",
        "    C_pad[:C.shape[0],:C.shape[1]] = C\n",
        "    return C_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZAyFCzEJILe"
      },
      "outputs": [],
      "source": [
        "def get_eigenvalues(molecule):\n",
        "    C_pad =get_Cmatrix(molecule)\n",
        "    e,_ = np.linalg.eigh(C_pad)\n",
        "    return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r19F0DFRYpOz",
        "outputId": "22453e3a-84c4-410d-f481-d48f7b482a1d"
      },
      "outputs": [],
      "source": [
        "e_ch4 = get_eigenvalues(molec)\n",
        "xtst = torch.tensor(e_ch4).reshape(1,23)\n",
        "\n",
        "model.eval()\n",
        "likelihood.eval()\n",
        "preds = likelihood(model(xtst))\n",
        "mean = preds.mean.cpu()\n",
        "print(mean)\n",
        "print(Xtot[0])\n",
        "print(ytot[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2ls7xNmPpIx",
        "outputId": "4befa36b-6b35-4784-d57c-e8b6518d417f"
      },
      "outputs": [],
      "source": [
        "# Benzene\n",
        "molec = '''\n",
        "  C        0.00000        1.40272        0.00000\n",
        "  H        0.00000        2.49029        0.00000\n",
        "  C       -1.21479        0.70136        0.00000\n",
        "  H       -2.15666        1.24515        0.00000\n",
        "  C       -1.21479       -0.70136        0.00000\n",
        "  H       -2.15666       -1.24515        0.00000\n",
        "  C        0.00000       -1.40272        0.00000\n",
        "  H        0.00000       -2.49029        0.00000\n",
        "  C        1.21479       -0.70136        0.00000\n",
        "  H        2.15666       -1.24515        0.00000\n",
        "  C        1.21479        0.70136        0.00000\n",
        "  H        2.15666        1.24515        0.00000\n",
        "  '''\n",
        "molec = molec.split()\n",
        "molec = np.array(molec)\n",
        "molec = molec.reshape(12,4)\n",
        "\n",
        "e = get_eigenvalues(molec)\n",
        "xtst = torch.tensor(e).reshape(1,23)\n",
        "\n",
        "model.eval()\n",
        "likelihood.eval()\n",
        "preds = likelihood(model(xtst))\n",
        "mean = preds.mean.cpu().detach().numpy()\n",
        "print('Atomization energy = %.3f kcal/mol'%float((mean[0]*std_data)+mu_data))\n",
        "# https://cccbdb.nist.gov/ea2.asp\n",
        "print('Benzene experimental atomization energy 1305.688 kcal/mol from NIST') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAvN367xQRGf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "chem4pb3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3bd1d19d093f1d1d5dd6cf1becc7a1cffecc3235fce6b74420ac04427a66c9c5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
