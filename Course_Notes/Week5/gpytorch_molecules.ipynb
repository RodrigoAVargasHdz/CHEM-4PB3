{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open on Google Colab\\\n",
    "https://colab.research.google.com/github/RodrigoAVargasHdz/CHEM-4PB3/blob/main/Course_Notes/Week5/gpytorch_molecules.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data an original model\n",
    "Load data from the [paper](th.fhi-berlin.mpg.de/site/uploads/Publications/QM-NJP_20130315.pdf)\n",
    "\n",
    "model was first introduce in 2012\n",
    "[paper](https://www.mrupp.info/Data/2012rtmvl_prl.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'C Matrix 0', 'C Matrix 1', 'C Matrix 2', 'C Matrix 3',\n",
      "       'C Matrix 4', 'C Matrix 5', 'C Matrix 6', 'C Matrix 7', 'C Matrix 8',\n",
      "       ...\n",
      "       'C Matrix 520', 'C Matrix 521', 'C Matrix 522', 'C Matrix 523',\n",
      "       'C Matrix 524', 'C Matrix 525', 'C Matrix 526', 'C Matrix 527',\n",
      "       'C Matrix 528', 'AtomizationEnergy'],\n",
      "      dtype='object', length=531)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load data\n",
    "data_url = \"https://github.com/RodrigoAVargasHdz/CHEM-4PB3/raw/main/Course_Notes/data/qm7.csv\"\n",
    "data = pd.read_csv(data_url)\n",
    "# print(data.head)\n",
    "print(data.columns)\n",
    "\n",
    "Xtot = data.drop(['Unnamed: 0','AtomizationEnergy'], axis=1).to_numpy()\n",
    "ytot = data['AtomizationEnergy'].to_numpy()  # [:,np.newaxis]\n",
    "Ctot = Xtot.reshape(Xtot.shape[0],23,23)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Eq. 2 in the [paper](https://www.mrupp.info/Data/2012rtmvl_prl.pdf), we see that the authors proposed the eigenvalues of the Coulomb matrix as the \n",
    "features of our model. \n",
    "1. $\\mathbf{\\epsilon}$ -> eigenvalues of the Coulomb matrix\n",
    "2. $C$ -> Coulomb matrix\n",
    "\n",
    "The elements of the C matrix are given by,\\\n",
    "$C_{ij} = \\Big\\{ \\begin{matrix} 0.5 Z_i^{2.4} \\;\\;\\;\\;\\text{if }\\;\\; i=j\\\\ \\frac{Z_iZ_j}{|R_i - R_j|} \\;\\;\\;\\;\\text{if }\\;\\; i\\neq j \\end{matrix}$,\n",
    "where,\n",
    "1. $R_{i}$ is the position of atom-i\n",
    "2. $Z_{i}$ is the atomic number of atom-i\n",
    "\n",
    "\n",
    "To compute the eigenvalues of C we can use numpy ``` np.linalg.eigh(C)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctot_eig = []\n",
    "for c in Ctot:\n",
    "    e,_ = np.linalg.eigh(c)\n",
    "    Ctot_eig.append(e)\n",
    "\n",
    "Ctot_eig = np.array(Ctot_eig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a GP using GPyTorch\n",
    "The kernel function proposed in the [paper](https://www.mrupp.info/Data/2012rtmvl_prl.pdf) is, (below if Equation (3))\\\n",
    "$K_{ij}=\\exp^{-\\frac{d(\\mathbf{C}_i,\\mathbf{C}_j)}{2\\ell^2}}$,\\\n",
    "where,\\\n",
    "$d(\\mathbf{C}_i,\\mathbf{C}_j) = d(\\mathbf{\\epsilon}_i,\\mathbf{\\epsilon}_j) = \\sqrt{\\sum_\\kappa |\\epsilon^\\kappa_i - \\epsilon^\\kappa_j|^2}$,\\\n",
    "where,\n",
    "* $\\epsilon^\\kappa_i$ is the $\\kappa$-th eigenvalue of the C matrix from molecule-i.\n",
    "\n",
    "$d(\\mathbf{C}_i,\\mathbf{C}_j)$ is simply an isotropic RBF kernel (can you see it?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data\n",
    "N = 1500\n",
    "Nval = 250\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Ctot_eig, ytot, test_size=ytot.shape[0] - N, random_state=0)\n",
    "X_test, y_test = X_test[:Nval], y_test[:Nval]\n",
    "Xtr, Xtst, ytr, ytst = X_train, X_test, y_train, y_test\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    Xtr = torch.from_numpy(Xtr).cuda()\n",
    "    ytr = torch.from_numpy(ytr).cuda()\n",
    "    Xtst = torch.from_numpy(Xtst).cuda()\n",
    "    ytst = torch.from_numpy(ytst).cuda()\n",
    "else:\n",
    "    Xtr = torch.from_numpy(Xtr)\n",
    "    ytr = torch.from_numpy(ytr)\n",
    "    Xtst = torch.from_numpy(Xtst)\n",
    "    ytst = torch.from_numpy(ytst)\n",
    "\n",
    "Xtot = torch.from_numpy(Xtot)\n",
    "ytot = torch.from_numpy(ytot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(Xtr, ytr, likelihood)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  likelihood.cuda()\n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/150 - Loss: 841314.359  noise: 0.693247\n",
      "lengthscale:  tensor([0.6931], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ravh011/Documents/McMaster/Courses/CHEM_4PB3_2022/Course_Notes/Week5/gpytorch_molecules.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ravh011/Documents/McMaster/Courses/CHEM_4PB3_2022/Course_Notes/Week5/gpytorch_molecules.ipynb#X32sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ravh011/Documents/McMaster/Courses/CHEM_4PB3_2022/Course_Notes/Week5/gpytorch_molecules.ipynb#X32sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m likelihood\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ravh011/Documents/McMaster/Courses/CHEM_4PB3_2022/Course_Notes/Week5/gpytorch_molecules.ipynb#X32sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m ypred \u001b[39m=\u001b[39m likelihood(model(Xtst))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ravh011/Documents/McMaster/Courses/CHEM_4PB3_2022/Course_Notes/Week5/gpytorch_molecules.ipynb#X32sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m mse \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(torch\u001b[39m.\u001b[39msum((ypred\u001b[39m.\u001b[39mmean \u001b[39m-\u001b[39m ytst)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ravh011/Documents/McMaster/Courses/CHEM_4PB3_2022/Course_Notes/Week5/gpytorch_molecules.ipynb#X32sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m mll_trajectory_tst\u001b[39m.\u001b[39mappend(mse\u001b[39m.\u001b[39mcpu())\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:320\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m# Make the prediction\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwith\u001b[39;00m settings\u001b[39m.\u001b[39mcg_tolerance(settings\u001b[39m.\u001b[39meval_cg_tolerance\u001b[39m.\u001b[39mvalue()):\n\u001b[0;32m--> 320\u001b[0m     predictive_mean, predictive_covar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction_strategy\u001b[39m.\u001b[39;49mexact_prediction(full_mean, full_covar)\n\u001b[1;32m    322\u001b[0m \u001b[39m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[1;32m    323\u001b[0m predictive_mean \u001b[39m=\u001b[39m predictive_mean\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39mbatch_shape, \u001b[39m*\u001b[39mtest_shape)\u001b[39m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/gpytorch/models/exact_prediction_strategies.py:273\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    268\u001b[0m     test_test_covar \u001b[39m=\u001b[39m joint_covar[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :]\n\u001b[1;32m    269\u001b[0m     test_train_covar \u001b[39m=\u001b[39m joint_covar[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train]\n\u001b[1;32m    271\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexact_predictive_mean(test_mean, test_train_covar),\n\u001b[0;32m--> 273\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexact_predictive_covar(test_test_covar, test_train_covar),\n\u001b[1;32m    274\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/gpytorch/models/exact_prediction_strategies.py:335\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_covar\u001b[0;34m(self, test_test_covar, test_train_covar)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[39m# In other cases - we'll use the standard infrastructure\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         \u001b[39mreturn\u001b[39;00m test_test_covar \u001b[39m+\u001b[39m MatmulLinearOperator(test_train_covar, covar_correction_rhs\u001b[39m.\u001b[39mmul(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m--> 335\u001b[0m precomputed_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcovar_cache\n\u001b[1;32m    336\u001b[0m covar_inv_quad_form_root \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exact_predictive_covar_inv_quad_form_root(precomputed_cache, test_train_covar)\n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(test_test_covar):\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/gpytorch/models/exact_prediction_strategies.py:229\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.covar_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    226\u001b[0m \u001b[39m@cached\u001b[39m(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcovar_cache\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcovar_cache\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    228\u001b[0m     train_train_covar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlik_train_train_covar\n\u001b[0;32m--> 229\u001b[0m     train_train_covar_inv_root \u001b[39m=\u001b[39m to_dense(train_train_covar\u001b[39m.\u001b[39;49mroot_inv_decomposition()\u001b[39m.\u001b[39mroot)\n\u001b[1;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exact_predictive_covar_inv_quad_form_cache(train_train_covar_inv_root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_test_train_covar)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/linear_operator/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:2124\u001b[0m, in \u001b[0;36mLinearOperator.root_inv_decomposition\u001b[0;34m(self, initial_vectors, test_vectors, method)\u001b[0m\n\u001b[1;32m   2117\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_shape \u001b[39m!=\u001b[39m initial_vectors\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m initial_vectors\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]:\n\u001b[1;32m   2118\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2119\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLinearOperator (size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) cannot be multiplied with initial_vectors (size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2120\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, initial_vectors\u001b[39m.\u001b[39mshape\n\u001b[1;32m   2121\u001b[0m             )\n\u001b[1;32m   2122\u001b[0m         )\n\u001b[0;32m-> 2124\u001b[0m inv_root \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root_inv_decomposition(initial_vectors)\n\u001b[1;32m   2125\u001b[0m \u001b[39mif\u001b[39;00m initial_vectors \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m initial_vectors\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2126\u001b[0m     inv_root \u001b[39m=\u001b[39m _postprocess_lanczos_root_inv_decomp(\u001b[39mself\u001b[39m, inv_root, initial_vectors, test_vectors)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py:693\u001b[0m, in \u001b[0;36mLinearOperator._root_inv_decomposition\u001b[0;34m(self, initial_vectors, test_vectors)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[39mReturns the (usually low-rank) inverse root of a LinearOperator of a PSD matrix.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[39m:return: A tensor :math:`\\mathbf R` such that :math:`\\mathbf R \\mathbf R^\\top \\approx \\mathbf A^{-1}`.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mroot_linear_operator\u001b[39;00m \u001b[39mimport\u001b[39;00m RootLinearOperator\n\u001b[0;32m--> 693\u001b[0m roots, inv_roots \u001b[39m=\u001b[39m RootDecomposition\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    694\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentation_tree(),\n\u001b[1;32m    695\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root_decomposition_size(),\n\u001b[1;32m    696\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[1;32m    697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m    698\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_shape,\n\u001b[1;32m    699\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmatrix_shape,\n\u001b[1;32m    700\u001b[0m     \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    701\u001b[0m     \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    702\u001b[0m     initial_vectors,\n\u001b[1;32m    703\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentation(),\n\u001b[1;32m    704\u001b[0m )\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m initial_vectors \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m initial_vectors\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    707\u001b[0m     add_to_cache(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mroot_decomposition\u001b[39m\u001b[39m\"\u001b[39m, RootLinearOperator(roots[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/linear_operator/functions/_root_decomposition.py:48\u001b[0m, in \u001b[0;36mRootDecomposition.forward\u001b[0;34m(ctx, representation_tree, max_iter, dtype, device, batch_shape, matrix_shape, root, inverse, initial_vectors, *matrix_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m matmul_closure \u001b[39m=\u001b[39m linear_op\u001b[39m.\u001b[39m_matmul\n\u001b[1;32m     47\u001b[0m \u001b[39m# Do lanczos\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m q_mat, t_mat \u001b[39m=\u001b[39m lanczos\u001b[39m.\u001b[39;49mlanczos_tridiag(\n\u001b[1;32m     49\u001b[0m     matmul_closure,\n\u001b[1;32m     50\u001b[0m     ctx\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m     51\u001b[0m     dtype\u001b[39m=\u001b[39;49mctx\u001b[39m.\u001b[39;49mdtype,\n\u001b[1;32m     52\u001b[0m     device\u001b[39m=\u001b[39;49mctx\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m     53\u001b[0m     matrix_shape\u001b[39m=\u001b[39;49mctx\u001b[39m.\u001b[39;49mmatrix_shape,\n\u001b[1;32m     54\u001b[0m     batch_shape\u001b[39m=\u001b[39;49mctx\u001b[39m.\u001b[39;49mbatch_shape,\n\u001b[1;32m     55\u001b[0m     init_vecs\u001b[39m=\u001b[39;49mctx\u001b[39m.\u001b[39;49minitial_vectors,\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m ctx\u001b[39m.\u001b[39mbatch_shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     q_mat \u001b[39m=\u001b[39m q_mat\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/linear_operator/utils/lanczos.py:77\u001b[0m, in \u001b[0;36mlanczos_tridiag\u001b[0;34m(matmul_closure, max_iter, dtype, device, matrix_shape, batch_shape, init_vecs, num_init_vecs, tol)\u001b[0m\n\u001b[1;32m     74\u001b[0m q_mat[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcopy_(q_0_vec)\n\u001b[1;32m     76\u001b[0m \u001b[39m# Initial alpha value: alpha_0\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m r_vec \u001b[39m=\u001b[39m matmul_closure(q_0_vec)\n\u001b[1;32m     78\u001b[0m alpha_0 \u001b[39m=\u001b[39m q_0_vec\u001b[39m.\u001b[39mmul(r_vec)\u001b[39m.\u001b[39msum(dim_dimension)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Initial beta value: beta_0\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/linear_operator/operators/added_diag_linear_operator.py:71\u001b[0m, in \u001b[0;36mAddedDiagLinearOperator._matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_matmul\u001b[39m(\u001b[39mself\u001b[39m, rhs: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39maddcmul(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_linear_op\u001b[39m.\u001b[39;49m_matmul(rhs), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_diag_tensor\u001b[39m.\u001b[39m_diag\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), rhs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/chem4pb3/lib/python3.9/site-packages/linear_operator/operators/dense_linear_operator.py:53\u001b[0m, in \u001b[0;36mDenseLinearOperator._matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_matmul\u001b[39m(\u001b[39mself\u001b[39m, rhs):\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmatmul(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtensor, rhs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters using ADAM\n",
    "\n",
    "# Use the adam optimizer\n",
    "# Includes GaussianLikelihood parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.2)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 150\n",
    "mll_trajectory = []\n",
    "mll_trajectory_tst = []\n",
    "for i in range(training_iter):\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(Xtr)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, ytr)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f  noise: %.6f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    print('lengthscale: ', model.covar_module.base_kernel.lengthscale[0])\n",
    "    mll_trajectory.append(loss.item())\n",
    "    optimizer.step()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "        ypred = likelihood(model(Xtst))\n",
    "        mse = torch.sqrt(torch.sum((ypred.mean - ytst)**2))\n",
    "        mll_trajectory_tst.append(mse.cpu())\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single molecule test case after training a GP model with GPytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' '0.00000' '1.40272' '0.00000']\n",
      " ['H' '0.00000' '2.49029' '0.00000']\n",
      " ['C' '-1.21479' '0.70136' '0.00000']\n",
      " ['H' '-2.15666' '1.24515' '0.00000']\n",
      " ['C' '-1.21479' '-0.70136' '0.00000']\n",
      " ['H' '-2.15666' '-1.24515' '0.00000']\n",
      " ['C' '0.00000' '-1.40272' '0.00000']\n",
      " ['H' '0.00000' '-2.49029' '0.00000']\n",
      " ['C' '1.21479' '-0.70136' '0.00000']\n",
      " ['H' '2.15666' '-1.24515' '0.00000']\n",
      " ['C' '1.21479' '0.70136' '0.00000']\n",
      " ['H' '2.15666' '1.24515' '0.00000']]\n"
     ]
    }
   ],
   "source": [
    "# Benzene\n",
    "molec = '''\n",
    "  C        0.00000        1.40272        0.00000\n",
    "  H        0.00000        2.49029        0.00000\n",
    "  C       -1.21479        0.70136        0.00000\n",
    "  H       -2.15666        1.24515        0.00000\n",
    "  C       -1.21479       -0.70136        0.00000\n",
    "  H       -2.15666       -1.24515        0.00000\n",
    "  C        0.00000       -1.40272        0.00000\n",
    "  H        0.00000       -2.49029        0.00000\n",
    "  C        1.21479       -0.70136        0.00000\n",
    "  H        2.15666       -1.24515        0.00000\n",
    "  C        1.21479        0.70136        0.00000\n",
    "  H        2.15666        1.24515        0.00000\n",
    "  '''\n",
    "molec = molec.split()\n",
    "molec = np.array(molec)\n",
    "molec = molec.reshape(12,4)\n",
    "print(molec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C' '0.00000' '1.40272' '0.00000']\n",
      "['H' '0.00000' '2.49029' '0.00000']\n",
      "['C' '-1.21479' '0.70136' '0.00000']\n",
      "['H' '-2.15666' '1.24515' '0.00000']\n",
      "['C' '-1.21479' '-0.70136' '0.00000']\n",
      "['H' '-2.15666' '-1.24515' '0.00000']\n",
      "['C' '0.00000' '-1.40272' '0.00000']\n",
      "['H' '0.00000' '-2.49029' '0.00000']\n",
      "['C' '1.21479' '-0.70136' '0.00000']\n",
      "['H' '2.15666' '-1.24515' '0.00000']\n",
      "['C' '1.21479' '0.70136' '0.00000']\n",
      "['H' '2.15666' '1.24515' '0.00000']\n",
      "[6, 1.0, 6, 1.0, 6, 1.0, 6, 1.0, 6, 1.0, 6, 1.0]\n"
     ]
    }
   ],
   "source": [
    "atomic_numbers = {'H':1.,'C':6}\n",
    "\n",
    "Z = []\n",
    "for x in molec:\n",
    "    print(x,)\n",
    "    zi = atomic_numbers[x[0]]\n",
    "    Z.append(zi)\n",
    "print(Z)\n",
    "Z = np.array(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36.8581052   5.51688651 25.66444132  2.77468376 14.81736583  1.75694151\n",
      "  12.83221194  1.54122393 14.81736583  1.75694151 25.66444132  2.77468376]\n",
      " [ 5.51688651  0.5         2.77469141  0.40155929  1.75694568  0.2318402\n",
      "   1.54122393  0.20077983  1.75694568  0.2318402   2.77469141  0.40155929]\n",
      " [25.66444132  2.77469141 36.8581052   5.51684358 25.66442387  2.77468101\n",
      "  14.81736583  1.75694568 12.83222066  1.54122138 14.81737601  1.75694273]\n",
      " [ 2.77468376  0.40155929  5.51684358  0.5         2.77468101  0.40155805\n",
      "   1.75694151  0.2318402   1.54122138  0.20077924  1.75694273  0.23183997]\n",
      " [14.81736583  1.75694568 25.66442387  2.77468101 36.8581052   5.51684358\n",
      "  25.66444132  2.77469141 14.81737601  1.75694273 12.83222066  1.54122138]\n",
      " [ 1.75694151  0.2318402   2.77468101  0.40155805  5.51684358  0.5\n",
      "   2.77468376  0.40155929  1.75694273  0.23183997  1.54122138  0.20077924]\n",
      " [12.83221194  1.54122393 14.81736583  1.75694151 25.66444132  2.77468376\n",
      "  36.8581052   5.51688651 25.66444132  2.77468376 14.81736583  1.75694151]\n",
      " [ 1.54122393  0.20077983  1.75694568  0.2318402   2.77469141  0.40155929\n",
      "   5.51688651  0.5         2.77469141  0.40155929  1.75694568  0.2318402 ]\n",
      " [14.81736583  1.75694568 12.83222066  1.54122138 14.81737601  1.75694273\n",
      "  25.66444132  2.77469141 36.8581052   5.51684358 25.66442387  2.77468101]\n",
      " [ 1.75694151  0.2318402   1.54122138  0.20077924  1.75694273  0.23183997\n",
      "   2.77468376  0.40155929  5.51684358  0.5         2.77468101  0.40155805]\n",
      " [25.66444132  2.77469141 14.81737601  1.75694273 12.83222066  1.54122138\n",
      "  14.81736583  1.75694568 25.66442387  2.77468101 36.8581052   5.51684358]\n",
      " [ 2.77468376  0.40155929  1.75694273  0.23183997  1.54122138  0.20077924\n",
      "   1.75694151  0.2318402   2.77468101  0.40155805  5.51684358  0.5       ]]\n",
      "36.85810519942594\n"
     ]
    }
   ],
   "source": [
    "XYZ = np.array(molec[:,1:],dtype=np.float32)\n",
    "diff =  XYZ[:,np.newaxis] - XYZ[np.newaxis,:]\n",
    "R = np.linalg.norm(diff,axis=-1)\n",
    "Rdiag = np.eye(R.shape[0])\n",
    "R = R + Rdiag\n",
    "R_inv = 1/R\n",
    "Zij = Z[:,np.newaxis] * Z[np.newaxis,:]\n",
    "C = Zij * R_inv\n",
    "C_diag = 0.5*np.power(Z, 2.4)\n",
    "C[np.diag_indices(R.shape[0])] = C_diag\n",
    "print(C)\n",
    "print((6**(2.4)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem4pb3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bd1d19d093f1d1d5dd6cf1becc7a1cffecc3235fce6b74420ac04427a66c9c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
