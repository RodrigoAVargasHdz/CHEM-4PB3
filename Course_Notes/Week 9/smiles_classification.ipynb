{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, rdDepictor\n",
    "from rdkit.Chem import PandasTools, Descriptors\n",
    "import py3Dmol\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from IPython.display import SVG\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of molecules using CNN #\n",
    "\n",
    "**Goals**\n",
    "1. Introduction to SMILES as molecular representation for ML models.\n",
    "2. Use ML models, more specifically **Convolutional NeuralNetworks** to classify molecules. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://github.com/RodrigoAVargasHdz/CHEM-4PB3/raw/w2024/Course_Notes/data/HIV.csv\"\n",
    "data = pd.read_csv(data_url)\n",
    "print('Total data:', data.count())\n",
    "data.head()\n",
    "\n",
    "data.hist(column='HIV_active')\n",
    "print('Possible values of HIV_active:', data['HIV_active'].unique())\n",
    "print('Possible values of activity:', data['activity'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some molecules that are not **HIV active**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(data, 'smiles')\n",
    "HIV_active_0 = data[data['HIV_active'] == 0]\n",
    "HIV_active_0_16 = PandasTools.FrameToGridImage(HIV_active_0[:9], column='ROMol', legendsCol='smiles',\n",
    "                                               molsPerRow=3, subImgSize=(300, 300))\n",
    "HIV_active_0_16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some molecules that are **HIV active**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(data, 'smiles')\n",
    "HIV_active_0 = data[data['HIV_active'] == 1]\n",
    "HIV_active_0_16 = PandasTools.FrameToGridImage(HIV_active_0[:9], column='ROMol', legendsCol='smiles',\n",
    "                                               molsPerRow=3, subImgSize=(300, 300))\n",
    "HIV_active_0_16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous class, we saw that a molecule written in the SMILES notation can be transformed into a *\"figure\"* using a dictionary of characters and the one-hot encoding transformation. <br>\n",
    "\n",
    "To create this dictionary, we first need to defined the maximum number of characters in a SMILE, meaning the length of the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMILES_CHARS = [\"7\", \"6\", \"o\", \"]\", \"3\", \"s\", \"(\", \"-\", \"S\", \"/\", \"B\", \"4\", \"[\", \")\", \"#\", \"I\",\n",
    "                \"l\", \"O\", \"H\", \"c\", \"1\", \"@\", \"=\", \"n\", \"P\", \"8\", \"C\", \"2\", \"F\", \"5\", \"r\", \"N\", \n",
    "                \"+\", \"\\\\\", \" \", \"Cu\", \".\", \"Si\", \"Se\", \"Na\", \"Li\", \"Ge\", \"K\", \"Zn\", \"Mo\", \"Rh\",\n",
    "                \"9\", \"p\", \"se\", \"Fe\", \"W\", \"Te\", \"Pd\", \"Ni\", \"As\", \"Pt\", \"Mg\", \"%\",\"U\",\"0\",\n",
    "                \"Tl\", \"Ga\", \"Au\", \"Ti\", \"Mn\", \"Bi\", \"Br\", \"Hg\", \"b\", \"Ca\", \"Ag\"]\n",
    "# Index\n",
    "smi2index = dict((c, i) for i, c in enumerate(SMILES_CHARS))\n",
    "\n",
    "\n",
    "def smiles_to_one_hot_and_list(smile, maxlen):\n",
    "    # Initialize a matrix filled with zeros up to maxlen\n",
    "    X = np.zeros((maxlen, len(SMILES_CHARS)))  # (maxlen, dictionary size)\n",
    "    smile_list = []  # List to store the split SMILES string\n",
    "    smile = smile.replace('\\n', '')\n",
    "    i = 0  # Position in the smile string\n",
    "    j = 0  # Position in the one-hot matrix\n",
    "    while i < len(smile):\n",
    "        # Check for two-character element\n",
    "        if i + 1 < len(smile) and smile[i:i+2] in smi2index:\n",
    "            X[j, smi2index[smile[i:i+2]]] = 1\n",
    "            smile_list.append(smile[i:i+2])\n",
    "            i += 2\n",
    "        # Single character element or symbol\n",
    "        elif smile[i] in smi2index:\n",
    "            X[j, smi2index[smile[i]]] = 1\n",
    "            smile_list.append(smile[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            print(smile)\n",
    "            print(smile[i])\n",
    "            assert 0\n",
    "            # raise ValueError(f\"Unrecognized SMILES character: {smile[i]}\")\n",
    "        j += 1\n",
    "        if j >= maxlen:\n",
    "            break  # Prevents exceeding the maximum length\n",
    "\n",
    "    return X.T, smile_list\n",
    "\n",
    "# Example usage\n",
    "smile = 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C'  # Example SMILES \n",
    "max_length_test = len(smile) + 5  # Example maximum length for SMILES representation\n",
    "one_hot_encoded_smile, smile_list = smiles_to_one_hot_and_list(\n",
    "    smile, max_length_test)\n",
    "print(smile_list)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(one_hot_encoded_smile, cmap='binary')\n",
    "plt.ylabel('Tokens')\n",
    "plt.xlabel('SMILES')\n",
    "\n",
    "plt.title('One-hot encoding for %s' % smile)\n",
    "plt.xticks(np.arange(len(list(smile_list))),\n",
    "           smile_list, fontsize=8)\n",
    "plt.yticks(np.arange(len(list(SMILES_CHARS))),\n",
    "           list(SMILES_CHARS), fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = AllChem.MolFromSmiles(smile)\n",
    "mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification tasks, having a balanced dataset is crucial for ensuring the model learns to accurately identify each class. When a dataset is imbalanced, with some classes significantly overrepresented compared to others, models tend to become biased towards the majority classes. This bias can lead to poorer performance on the minority classes, as the model might not learn their characteristics adequately. Essentially, the model may simply \"learn\" to predict the majority class most of the time, because doing so minimizes its error on the training data. However, such a model is not genuinely understanding or distinguishing between the classes effectively. <br>\n",
    "\n",
    "Balancing the dataset, either through undersampling the majority classes, oversampling the minority classes, or employing synthetic data generation techniques like SMOTE, helps in creating a more equitable training environment. This balanced approach encourages the model to pay equal attention to learning the distinctive features of each class, leading to better generalization and a more robust performance across all classes, not just the predominant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_negative = data[data['HIV_active'] == 0]\n",
    "data_positive = data[data['HIV_active'] == 1]\n",
    "print(data_negative.count())\n",
    "print(data_positive.count())\n",
    "\n",
    "# balanced dataset\n",
    "n_positive = len(data_positive)\n",
    "data_negative_red = data_negative.sample(n_positive)\n",
    "\n",
    "balanced_data = pd.concat([data_negative_red, data_positive], axis=0)\n",
    "print(balanced_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "for si in data['smiles']:\n",
    "    if len(si) > max_length:\n",
    "        max_length = len(si)\n",
    "\n",
    "print('Max Molecule length', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Data loader for this dataset.\n",
    "1. We will transform each smile into its \"figure\" representation\n",
    "2. Because we are working with two-classes, 'active' and 'inactive'. We also need to transform the label/class to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, smiles_all, labels_all, max_length):\n",
    "        self.labels = labels_all\n",
    "        self.smiles = smiles_all\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        si = self.smiles[idx]\n",
    "        labels = self.labels[idx]\n",
    "    \n",
    "        mi,si_list = smiles_to_one_hot_and_list(si,self.max_length)\n",
    "        \n",
    "        molecules_torch = torch.from_numpy(mi).float()\n",
    "        labels_one_hot = F.one_hot(torch.from_numpy(np.array(labels)),num_classes=2)\n",
    "        return molecules_torch.unsqueeze(0), labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = balanced_data\n",
    "train_size = int(0.8 * len(data_full))  # 80% for training\n",
    "validation_size = len(data_full) - train_size  # 20% for validation\n",
    "print('Training data', train_size)\n",
    "print('Test data', validation_size)\n",
    "# train_dataset, validation_dataset = random_split(\n",
    "#     data_full, [train_size, validation_size])\n",
    "tr_dataset = data_full.sample(train_size)\n",
    "val_dataset = data_full.sample(validation_size)\n",
    "                            \n",
    "\n",
    "\n",
    "training_data = CustomDataset(\n",
    "    tr_dataset['smiles'].to_list(), tr_dataset['HIV_active'].to_list(), max_length)\n",
    "train_dataloader = DataLoader(training_data, batch_size=128, shuffle=True)\n",
    "train_molecules, train_labels = next(iter(train_dataloader))\n",
    "\n",
    "print('Size of the training data')\n",
    "print(train_molecules.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5,padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )        # fully connected layer, output 10 classes\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16 * 15 * 143, 512),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # print(x.shape)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = self.conv2(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        # print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        # print(x.shape)\n",
    "        output = self.fc3(x)\n",
    "        return output   # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_data, training_epochs=60):\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        training_data, batch_size=64, shuffle=True)\n",
    "\n",
    "    iterator = tqdm.notebook.tqdm(range(training_epochs))\n",
    "\n",
    "    # Run the training loop (epochs)\n",
    "    loss_trajectory = []\n",
    "    for epoch in iterator:\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = []\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, targets = data\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_function(outputs, targets.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            # current_loss += loss.item()\n",
    "            current_loss.append(loss.item())\n",
    "        # print('Epoch %s: %.4f +- %.4f'%(epoch,np.array(current_loss).mean(),np.array(current_loss).std()))\n",
    "        iterator.set_postfix(loss=torch.tensor(current_loss).mean())\n",
    "        loss_trajectory.append(current_loss)\n",
    "        # Process is complete.\n",
    "    return loss_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "print(train_molecules.shape)\n",
    "labels = cnn(train_molecules)\n",
    "print(labels)\n",
    "\n",
    "loss_trj = train(cnn, training_data,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix ##\n",
    "A Confusion Matrix is a powerful tool used in machine learning to evaluate the performance of classification models. It is a table that visualizes the accuracy of a model by comparing the actual versus predicted classifications. The matrix is divided into four parts: True Positives (TP), where the model correctly predicts the positive class; True Negatives (TN), where the model correctly predicts the negative class; False Positives (FP), where the model incorrectly predicts the positive class; and False Negatives (FN), where the model incorrectly predicts the negative class. This breakdown allows not only for the calculation of overall accuracy but also for more nuanced performance metrics such as precision, recall, and the F1 score. By providing a detailed view of how a model is performing across different classes, the Confusion Matrix helps in identifying specific areas where the model may be struggling, making it invaluable for diagnosing and improving classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "true_labels = np.random.binomial(1, 0.5, 100)\n",
    "print(true_labels)\n",
    "assert 0\n",
    "# predictions = np.random.binomial(1, 0.5, 100)\n",
    "cnn.eval()\n",
    "cnn()\n",
    "\n",
    "\n",
    "val_data = CustomDataset(\n",
    "    val_dataset['smiles'].to_list(), val_dataset['HIV_active'].to_list(), max_length)\n",
    "train_dataloader = DataLoader(val_data, batch_size=validation_size, shuffle=True)\n",
    "val_molecules, val_labels = next(iter(train_dataloader))\n",
    "\n",
    "\n",
    "true_labels = val_labels\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(['Class 0', 'Class 1'])\n",
    "ax.yaxis.set_ticklabels(['Class 0', 'Class 1'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem4pb3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
