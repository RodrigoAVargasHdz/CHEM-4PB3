{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/RodrigoAVargasHdz/CHEM-4PB3/blob/w2024/Course_Notes/Week%206/TanimotoKernel.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB89nVxL4ryg",
        "outputId": "23821751-cf6b-40d8-91f8-4bd089af76fb"
      },
      "outputs": [],
      "source": [
        "!pip install gpytorch\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import gpytorch\n",
        "from gpytorch.kernels import Kernel\n",
        "from rdkit.Chem import AllChem, Descriptors, MolFromSmiles, MolToSmiles\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "from gpytorch.constraints import Positive\n",
        "from torch import Tensor\n",
        "import torch\n",
        "from gpytorch.kernels import Kernel\n",
        "from gpytorch.constraints import Positive"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pTGMBJ5ZSE3Y"
      },
      "source": [
        "To open on Google Colab [link](https://colab.research.google.com/github/RodrigoAVargasHdz/CHEM-4PB3/blob/main/Course_Notes/Week6/TanimotoKernel.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LTko0HmS8Fg"
      },
      "source": [
        "# Kernel for strings #\n",
        "\n",
        "The kernel between two strings $\\mathbf{x}$ and $\\mathbf{x}'$ can be defined as,\n",
        "$$\n",
        "k(x,x') = \\sum_{a\\in{\\cal A}^*}\\omega_s \\phi_s(\\mathbf{x})\\phi_s(\\mathbf{x}'),\n",
        "$$\n",
        "where \n",
        "*  $\\phi_s(\\mathbf{x})$ denote the number of times that substring $s$ appears in string $\\mathbf{x}$\n",
        "* ${\\cal A}$ is the alphabet of characters.\n",
        "* $\\omega_s$ is a non-negative weight for substring $s$\n",
        "</br>\n",
        "</br>\n",
        "\n",
        "(**Example from Ref. [2](https://papers.nips.cc/paper/2000/file/68c694de94e6c110f42e587e8e48d852-Paper.pdf)**)\\\n",
        "![Arrays](https://raw.github.com/RodrigoAVargasHdz/CHEM-4PB3/master/Course_Notes/Figures/StringKernel.png)\n",
        "\n",
        "\n",
        "</br>\n",
        "</br>\n",
        "\n",
        "**References**\n",
        "1. [GP Book, Chapter 4, Section 4.4](https://gaussianprocess.org/gpml/chapters/) \n",
        "2. [(paper) Text classification with string kernels](https://papers.nips.cc/paper/2000/file/68c694de94e6c110f42e587e8e48d852-Paper.pdf)\n",
        "3. [(paper) GAUCHE: A Library for Gaussian Processes in Chemistry](https://ml4physicalsciences.github.io/2022/files/NeurIPS_ML4PS_2022_75.pdf)\n",
        "4. [(Wiki) String kernels](https://en.wikipedia.org/wiki/String_kernel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kKCzBy4ZnR-"
      },
      "source": [
        "# Kernels for molecules #\n",
        "**Reference**: [paper](https://papers.nips.cc/paper/2000/file/68c694de94e6c110f42e587e8e48d852-Paper.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scalar product kernel ##\n",
        "$k_{\\text{Scalar Product}}(\\mathbf{x},\\mathbf{x}') = \\ell \\cdot \\langle \\mathbf{x},\\mathbf{x}' \\rangle$, \\\n",
        "where\n",
        "* $\\langle \\mathbf{x},\\mathbf{x}' \\rangle$ is the  Euclidean inner product; $\\langle \\mathbf{x},\\mathbf{x}' \\rangle = \\sum_i x_i x'_i$.\n",
        "* $\\ell$ is a scalar signal variance hyperparameter.\n",
        "</br>\n",
        "</br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tanimoto kernel ##\n",
        "General similarity metric for **binary attributes**, used in [Ref.](https://doi.org/10.1016/j.neunet.2005.07.009) for cheminformatics.\n",
        "\n",
        "$k_{\\text{Tanimoto}}(\\mathbf{x},\\mathbf{x}') = \\ell \\cdot \\frac{\\langle \\mathbf{x},\\mathbf{x}' \\rangle}{\\|\\mathbf{x} \\|^2 + \\|\\mathbf{x}'\\|^2 - \\langle \\mathbf{x},\\mathbf{x}' \\rangle}$, \\\n",
        "where\n",
        "* $\\| \\;\\cdot\\; \\|$ is the Euclidian norm\n",
        "* $\\mathbf{x}$ is a binary vector, $x_i = \\{0,1\\}$\n",
        "</br>\n",
        "</br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph kernel ##\n",
        "$k_{\\text{Gprah}}(g,g') = \\ell \\cdot \\langle \\phi(g),\\phi(g') \\rangle_{{\\cal H}}$,\n",
        "where,\n",
        "* $\\langle \\phi(g),\\phi(g') \\rangle_{{\\cal H}}$  measures the similarity betweene two molecular graphs. Related to graph isomorphism. \n",
        "* $\\ell$ is a scalar signal variance hyperparameter.\n",
        "\n",
        "The graph kernel will be used this week [link](https://colab.research.google.com/github/RodrigoAVargasHdz/CHEM-4PB3/blob/main/Course_Notes/Week5/gpytorch_molecules.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyODuoF-ZscZ"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmVBPP_IhLIz"
      },
      "source": [
        "## Tanimoto kernel in Torch\n",
        "Code is based on this [online tutorial](https://towardsdatascience.com/gaussian-process-regression-on-molecules-in-gpflow-ee6fedab2130), where $k_{\\text{Tanimoto}}(\\cdot,â‹…)$ was coded in TensorFlow. \\\n",
        "For defining your own kernel in Gpytorch, one can follow the following [tutorial](https://docs.gpytorch.ai/en/stable/examples/00_Basic_Usage/Implementing_a_custom_Kernel.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDG5f2duzf6K"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from ChatGPT 2023\n",
        "# '''Write me a code compatible with GPyTorch for the Tanimoto kernel function'''\n",
        "# '''remove the lengthscale parameter'''\n",
        "class TanimotoKernel(gpytorch.kernels.Kernel):\n",
        "    def __init__(self, active_dims=None):\n",
        "        super(TanimotoKernel, self).__init__(active_dims=active_dims)\n",
        "        self.register_parameter(\n",
        "            name=\"raw_variance\", parameter=torch.nn.Parameter(torch.ones(1))\n",
        "        )\n",
        "        self.register_constraint(\"raw_variance\", gpytorch.constraints.Positive())\n",
        "\n",
        "    @property\n",
        "    def variance(self):\n",
        "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
        "\n",
        "    @variance.setter\n",
        "    def variance(self, value):\n",
        "        self.raw_variance = self.raw_variance_constraint.inverse_transform(value)\n",
        "\n",
        "    def forward(self, x1, x2, **params):\n",
        "        x1_ = x1.unsqueeze(-2)\n",
        "        x2_ = x2.unsqueeze(-3)\n",
        "        numerator = torch.sum(x1_ * x2_, dim=-1)\n",
        "        denominator = torch.sum(x1_ + x2_ - x1_ * x2_, dim=-1)\n",
        "        return self.variance * numerator / denominator\n",
        "    '''\n",
        "    # def forward(self, x1, x2, **params):\n",
        "    #     x1_ = x1.unsqueeze(-2)\n",
        "    #     x2_ = x2.unsqueeze(-3)\n",
        "    #     numerator = torch.sum(x1_ * x2_, dim=-1)\n",
        "    #     denominator = torch.sum(x1_ ** 2, dim=-1) + \\\n",
        "    #         torch.sum(x2_ ** 2, dim=-1) - numerator\n",
        "    #     return self.raw_variance * numerator / denominator  \n",
        "    '''\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajZLieLQozB3",
        "outputId": "7274f9e9-0219-43f8-dfec-042f0a20abfe"
      },
      "outputs": [],
      "source": [
        "n,d = 2, 5\n",
        "x1 = torch.randint(0, 2, (n,d))\n",
        "print('Random vectors')\n",
        "print(x1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uD9y1mQuBZi",
        "outputId": "f0c03ee1-41da-4853-dd9c-7611a216294d"
      },
      "outputs": [],
      "source": [
        "print(x1.unsqueeze(-2).shape)\n",
        "print(x1.unsqueeze(-2))\n",
        "print(x1.unsqueeze(-3).shape)\n",
        "print(x1.unsqueeze(-3))\n",
        "print('*')\n",
        "\n",
        "print(torch.sum(x1.unsqueeze(-2) * x1.unsqueeze(-3), dim=-1))\n",
        "print(torch.tensordot(x1,x1, dims=([-1],[-1])))\n",
        "print('*')\n",
        "\n",
        "kernel = TanimotoKernel()\n",
        "K = kernel.forward(x1,x1) ## is this correct?\n",
        "print('Kernel matrix')\n",
        "print(K)\n",
        "print('Kernel parameter')\n",
        "print(kernel.raw_variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPT4 2024 ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TanimotoKernel(Kernel):\n",
        "    has_lengthscale = False\n",
        "\n",
        "    def __init__(self, variance=None, **kwargs):\n",
        "        super(TanimotoKernel, self).__init__(**kwargs)\n",
        "\n",
        "        # Initialize the variance (outputscale) parameter\n",
        "        if variance is None:\n",
        "            self.raw_outputscale = torch.nn.Parameter(\n",
        "                torch.log(torch.exp(torch.tensor(1.))-1))\n",
        "        else:\n",
        "            self.raw_outputscale = torch.nn.Parameter(torch.tensor(variance))\n",
        "\n",
        "        self.register_constraint(\"raw_outputscale\", Positive())\n",
        "\n",
        "    @property\n",
        "    def outputscale(self):\n",
        "        return self.raw_outputscale_constraint.transform(self.raw_outputscale)\n",
        "\n",
        "    @outputscale.setter\n",
        "    def outputscale(self, value):\n",
        "        self._set_outputscale(value)\n",
        "\n",
        "    def forward(self, x1, x2, diag=False, **params):\n",
        "        \"\"\"\n",
        "        Compute the scaled Tanimoto kernel between inputs x1 and x2.\n",
        "\n",
        "        Args:\n",
        "            x1 (Tensor): The first input tensor with shape (..., n, d) where n is the number of points\n",
        "                         and d is the dimensionality of each point.\n",
        "            x2 (Tensor): The second input tensor with shape (..., m, d) where m is the number of points\n",
        "                         and d is the dimensionality of each point.\n",
        "            diag (bool, optional): Whether to return the diagonal of the kernel matrix rather than the full\n",
        "                                   kernel matrix. Defaults to False.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The computed kernel matrix scaled by the variance parameter.\n",
        "        \"\"\"\n",
        "        prod = x1.matmul(x2.transpose(-2, -1))\n",
        "        x1_sq = x1.pow(2).sum(dim=-1, keepdim=True)\n",
        "        x2_sq = x2.pow(2).sum(dim=-1, keepdim=True).transpose(-2, -1)\n",
        "\n",
        "        base = x1_sq + x2_sq - prod\n",
        "        kernel_matrix = prod / base\n",
        "\n",
        "        # Scale the kernel matrix by the variance parameter\n",
        "        kernel_matrix *= self.outputscale\n",
        "\n",
        "        if diag:\n",
        "            return kernel_matrix.diag()\n",
        "        else:\n",
        "            return kernel_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VR_hsoFicf4"
      },
      "source": [
        "# Example Caffeine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yan0PJKRvIxW"
      },
      "outputs": [],
      "source": [
        "def get_fingerprints(m_smiles,radius=2):\n",
        "  m = MolFromSmiles(m_smiles)\n",
        "  m_fingerprints = AllChem.GetMorganFingerprintAsBitVect(m, radius=radius, nBits=2048)\n",
        "  return np.asarray(m_fingerprints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "4cCLNej25j5Z",
        "outputId": "541b6c62-fff4-441a-dccb-6a11a6e3dfac"
      },
      "outputs": [],
      "source": [
        "caff_sm = 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C'\n",
        "m = MolFromSmiles(caff_sm)\n",
        "x_caff_fp = get_fingerprints(caff_sm)\n",
        "print(x_caff_fp)\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wifKQjwA9zqO"
      },
      "source": [
        "Molecules similar to caffeine [link](https://www.acs.org/education/resources/highschool/chemmatters/past-issues/archive-2013-2014/caffeine.html)\\\n",
        "[Paraxanthine](https://en.wikipedia.org/wiki/Paraxanthine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "hZK1nAe-6smi",
        "outputId": "dc4b8f99-64ea-431b-fa68-70c914b2e724"
      },
      "outputs": [],
      "source": [
        "# Paraxanthine\n",
        "parax_sm = 'O=C2Nc1ncn(c1C(=O)N2C)C'\n",
        "m1 = MolFromSmiles(parax_sm)\n",
        "x_parax_fp = get_fingerprints(parax_sm)\n",
        "m1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0i2sY8L_yMr"
      },
      "source": [
        "Evaluate the Tanimoto kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPrsDhSe7mEs",
        "outputId": "a87593ca-1d01-4ed8-8b4c-8cb92eb0805f"
      },
      "outputs": [],
      "source": [
        "x_caff = torch.from_numpy(x_caff_fp).unsqueeze(0)\n",
        "x_parax = torch.from_numpy(x_parax_fp).unsqueeze(0)\n",
        "print('Tanimoto kernel for, Caffeine-Caffeine: ',kernel.forward(x_caff,x_caff))\n",
        "print('Tanimoto kernel for, Caffeine-Paraxanthine: ',kernel.forward(x_caff,x_parax))\n",
        "print('Tanimoto kernel for, Paraxanthine-Paraxanthine: ',kernel.forward(x_parax,x_parax))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkw0nGLK-zJa"
      },
      "source": [
        "# More data!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paSfRV_m8rE3",
        "outputId": "9c132661-d487-440a-b9f6-242af8f4ec4e"
      },
      "outputs": [],
      "source": [
        "data_url = \"https://github.com/RodrigoAVargasHdz/CHEM-4PB3/raw/main/Course_Notes/data/solubility.csv\"\n",
        "data = pd.read_csv(data_url)\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGIh88D7IVk5",
        "outputId": "02452e84-4182-48db-cfa4-5e7a08c1994a"
      },
      "outputs": [],
      "source": [
        "# print 10 molecules\n",
        "print(data['SMILES'][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3JTBl5QIa0c"
      },
      "outputs": [],
      "source": [
        "# compute the FingerPrints for all molecules\n",
        "X_fp = []\n",
        "molecules = data['SMILES']#[:1000]\n",
        "for m in molecules:\n",
        "  x = get_fingerprints(m)\n",
        "  X_fp.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "uCGDchmjw8iI",
        "outputId": "9d649e3e-06b2-49d3-b7b4-8c7acd55737a"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# # compute K(caffeine, molecule)\n",
        "X_fp = torch.from_numpy(np.asarray(X_fp))\n",
        "k_t = kernel.forward(x_caff,X_fp)\n",
        "# print(k_t[:1000])\n",
        "\n",
        "# from torch to numpy (don't forget!!)\n",
        "k_values = k_t.detach().numpy()\n",
        "k_values = k_values.flatten()\n",
        "  \n",
        "plt.figure(figsize=(10,8))\n",
        "plt.hist(k_values, bins=100)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.xlabel('Tanimoto Kernel for Caffeine',fontsize=15)\n",
        "plt.ylabel('Counts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i_max = np.argmax(k_values)\n",
        "smiles_max = data['SMILES'][i_max]\n",
        "print(smiles_max)\n",
        "i_min = np.argmin(k_values)\n",
        "smiles_min = data['SMILES'][i_min]\n",
        "print(smiles_min)\n",
        "\n",
        "molecule1 = MolFromSmiles(smiles_max)\n",
        "molecule2 = MolFromSmiles(smiles_min)\n",
        "\n",
        "mols = [molecule1, molecule2]\n",
        "img = Draw.MolsToGridImage(mols, molsPerRow=2, subImgSize=(\n",
        "    200, 200), legends=['Molecule MAX', 'Molecule MIN'])\n",
        "\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def are_smiles_equal(smiles1, smiles2):\n",
        "    # Convert the SMILES strings to RDKit molecule objects\n",
        "    mol1 = MolFromSmiles(smiles1)\n",
        "    mol2 = MolFromSmiles(smiles2)\n",
        "\n",
        "    # Generate canonical SMILES for each molecule\n",
        "    canonical_smiles1 = MolToSmiles(mol1)\n",
        "    canonical_smiles2 = MolToSmiles(mol2)\n",
        "\n",
        "    # Compare the canonical SMILES strings\n",
        "    return canonical_smiles1 == canonical_smiles2\n",
        "\n",
        "are_equal = are_smiles_equal(caff_sm, smiles_max)\n",
        "print(f\"Are the two SMILES equal? {are_equal}\")\n",
        "\n",
        "are_equal = are_smiles_equal(caff_sm, smiles_min)\n",
        "print(f\"Are the two SMILES equal? {are_equal}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lPU_OELyQhD"
      },
      "source": [
        "## Train a GP (GPyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yBsY1AGxL3o",
        "outputId": "37906b0c-95b0-454c-f8f6-fc36537d84df"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# data\n",
        "# Xtot_np = k_values[:,np.newaxis]\n",
        "Xtot_np = np.asarray(X_fp)\n",
        "ytot_np = data['Solubility'].to_numpy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(ytot_np[:,np.newaxis])\n",
        "ytot_np = scaler.transform(ytot_np[:,np.newaxis])\n",
        "ytot_np = ytot_np.ravel()\n",
        "\n",
        "print(Xtot_np.shape,ytot_np.shape)\n",
        "\n",
        "N = 800 #2500\n",
        "Nval = 5000\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xtot_np, ytot_np, \n",
        "                                                    test_size=ytot_np.shape[0] - N, random_state=1)\n",
        "if Nval > 0:\n",
        "    X_test, y_test = X_test[:Nval], y_test[:Nval]\n",
        "    Xtr, Xtst, ytr, ytst = X_train, X_test, y_train, y_test\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    Xtr = torch.from_numpy(Xtr).cuda()\n",
        "    ytr = torch.from_numpy(ytr).float().cuda()\n",
        "else:\n",
        "    Xtr = torch.from_numpy(Xtr)\n",
        "    ytr = torch.from_numpy(ytr).float()\n",
        "\n",
        "Xtst = torch.from_numpy(Xtst).double()\n",
        "ytst = torch.from_numpy(ytst).float()\n",
        "\n",
        "Xtot = torch.from_numpy(Xtot_np)\n",
        "ytot = torch.from_numpy(ytot_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONkMRcgnz98k"
      },
      "outputs": [],
      "source": [
        "class ExactGPModel(gpytorch.models.ExactGP):\n",
        "    def __init__(self, train_x, train_y, likelihood):\n",
        "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
        "        self.mean_module = gpytorch.means.ConstantMean()\n",
        "        self.covar_module = TanimotoKernel()\n",
        "        # self.covar_module = gpytorch.kernels.ScaleKernel(\n",
        "        #     gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[1]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVa65cegyna0"
      },
      "outputs": [],
      "source": [
        "# initialize likelihood and model\n",
        "\n",
        "# likelihood = gpytorch.likelihoods.GaussianLikelihood().double()\n",
        "# likelihood.noise = 1e-5  # Some small value, but don't make it too small or numerical performance will suffer. I recommend 1e-4.\n",
        "# likelihood.noise_covar.raw_noise.requires_grad_(False)\n",
        "\n",
        "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(1e-6)).double()\n",
        "likelihood.noise = 1e-5 \n",
        "\n",
        "model = ExactGPModel(Xtr, ytr, likelihood).double()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    likelihood.cuda()\n",
        "    model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dtt1bK6wCX-_"
      },
      "outputs": [],
      "source": [
        "kernel = TanimotoKernel()\n",
        "K = kernel.forward(Xtr,Xtr)\n",
        "for i, k in enumerate(K):\n",
        "  if not torch.any(torch.isnan(k)):\n",
        "    print(i)\n",
        "    print(Xtr[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OgDhyMyIz3_J",
        "outputId": "94d7bf89-9459-447f-9ef9-a0bb37dbdd48"
      },
      "outputs": [],
      "source": [
        "# Find optimal model hyperparameters using ADAM\n",
        "\n",
        "# Use the adam optimizer\n",
        "# Includes GaussianLikelihood parameters\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "# \"Loss\" for GPs - the marginal log likelihood\n",
        "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "training_iter = 250\n",
        "mll_trajectory = []\n",
        "mll_trajectory_tst = []\n",
        "for i in range(training_iter+1):\n",
        "    model.train()\n",
        "    likelihood.train()\n",
        "    # Zero gradients from previous iteration\n",
        "    optimizer.zero_grad()\n",
        "    # Output from model\n",
        "    output = model(Xtr)\n",
        "    # Calc loss and backprop gradients\n",
        "    loss = -mll(output, ytr)\n",
        "    loss.backward()\n",
        "    mll_trajectory.append(loss.item())\n",
        "\n",
        "    if (i % 25) == 0.:\n",
        "      print('Iter %d/%d - Loss: %.5f  noise: %.6f' % (\n",
        "          i, training_iter, loss.item(),\n",
        "          model.likelihood.noise.item()\n",
        "      ))\n",
        "      print('sigma: ', model.covar_module.variance.item())\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBFpN4AeJarh"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKwi4YCU0ZnL"
      },
      "outputs": [],
      "source": [
        "# Prediction with GPyTorch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# \tIn all other cases, he suggests using a power of 2 as the mini-batch size.\n",
        "# \tSo the minibatch should be 64, 128, 256, 512, or 1024 elements large.\n",
        "\n",
        "\n",
        "dummy_test_y = torch.full_like(Xtst, dtype=torch.long, fill_value=0)\n",
        "test_dataset = TensorDataset(Xtst, dummy_test_y)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
        "\n",
        "means = torch.tensor([0.])\n",
        "stds = torch.tensor([[0.,0]])\n",
        "\n",
        "model.eval()\n",
        "likelihood.eval()\n",
        "with torch.no_grad():\n",
        "    for x_batch, _ in test_loader:\n",
        "      if torch.cuda.is_available():\n",
        "          xb = x_batch.cuda()\n",
        "      else:\n",
        "          xb = x_batch\n",
        "      preds = likelihood(model(xb))\n",
        "      mean = preds.mean.cpu()\n",
        "      means = torch.cat([means, mean])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "sCLCHOXyJfhA",
        "outputId": "8b9a0c0c-7e69-4790-bcd6-01281ab0cada"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "ytot_gp = means[1:].cpu().numpy() # torch to numpy \n",
        "ytst.cpu()\n",
        "r2 = r2_score(ytot_gp,ytst.cpu())\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(ytot_gp,ytst.cpu(),s=5)\n",
        "\n",
        "low = np.min(np.stack((ytot_gp,ytst.cpu())).flatten())\n",
        "high = np.max(np.stack((ytot_gp,ytst.cpu())).flatten())\n",
        "plt.plot([low, high], [low, high], ls=\"--\", c=\"red\",lw=3.)\n",
        "\n",
        "plt.title('Solubility (N=%s), $R^{2}$ = %.3f'%(N,r2),fontsize=18)\n",
        "# plt.text(0.02,0.08,r'$R^{2}$ = %.3f'%r2,fontsize=18)\n",
        "plt.xlabel('GP prediction',fontsize=18)\n",
        "plt.ylabel('Data',fontsize=18)\n",
        "# plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "chem4pb3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "3bd1d19d093f1d1d5dd6cf1becc7a1cffecc3235fce6b74420ac04427a66c9c5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
