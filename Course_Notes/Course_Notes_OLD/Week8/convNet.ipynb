{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open on Google Colab [link](https://colab.research.google.com/github/RodrigoAVargasHdz/CHEM-4PB3/blob/main/Course_Notes/Week8/convNet.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rdkit-pypi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHEMINFORMATICS in the era of ML\n",
    "\n",
    "[paper](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2523-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# rdkit stuff\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from https://github.com/aspuru-guzik-group/chemical_vae\n",
    "data_url = \"https://github.com/aspuru-guzik-group/chemical_vae/raw/main/models/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv\"\n",
    "data_total = pd.read_csv(data_url)\n",
    "\n",
    "# The total number of data points is HUGE, lets sample 10K random\n",
    "N = 10000\n",
    "data = data_total.sample(N)\n",
    "print(data.head)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Extra dataset for Classification for Toxicity \n",
    "# be careful as the data set is UNBALANCE\n",
    "# data_url = \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/clintox.csv.gz\"\n",
    "# df = pd.read_csv(data_url, compression='gzip', header=0,\n",
    "                #  sep=',', quotechar='\"', error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(data_total.logP.to_numpy(),bins=1000,density=True,label='N = %s'%data_total.shape[0])\n",
    "plt.hist(data.logP.to_numpy(),bins=200,density=True,label='N = %s'%data.shape[0])\n",
    "plt.xlabel('logP')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canonical_smiles(molec_smiles):\n",
    "    molecule = AllChem.MolFromSmiles(molec_smiles)\n",
    "    return AllChem.MolToSmiles(molecule, canonical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_all = data.smiles.to_list()\n",
    "length_smiles = []\n",
    "for s in smiles_all:\n",
    "    length_smiles.append(len(s))\n",
    "length_smiles = np.array(length_smiles)\n",
    "\n",
    "\n",
    "i_min = np.argmin(length_smiles)\n",
    "i_max = np.argmax(length_smiles)\n",
    "print(i_min,i_max)\n",
    "print('Smallest molecule (%s), %s'%(length_smiles[i_min],smiles_all[i_min]))\n",
    "print('Largest molecule (%s), %s' % (length_smiles[i_max], smiles_all[i_max]))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.hist(length_smiles,bins=100)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Length of SMILES',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALPHABET: define SMILES characters \n",
    "\n",
    "max_len = 100\n",
    "SMILES_CHARS = [\"7\", \"6\", \"o\", \"]\", \"3\", \"s\", \"(\", \"-\", \"S\", \"/\", \"B\", \"4\", \"[\", \")\", \"#\", \"I\",\n",
    "                \"l\", \"O\", \"H\", \"c\", \"1\", \"@\", \"=\", \"n\", \"P\", \"8\", \"C\", \"2\", \"F\", \"5\", \"r\", \"N\", \"+\", \"\\\\\", \" \"]\n",
    "# index\n",
    "smi2index = dict((c, i) for i, c in enumerate(SMILES_CHARS))\n",
    "\n",
    "\n",
    "def smiles_to_one_hot(smiles, maxlen=max_len):\n",
    "    X = np.zeros((maxlen, len(SMILES_CHARS)))  # (maxlen, dictionary)\n",
    "    # print(smiles,type(smiles))\n",
    "    smiles = smiles.replace('\\n', '')\n",
    "    for i, c in enumerate(smiles):\n",
    "        X[i, smi2index[c]] = 1\n",
    "    return X\n",
    "\n",
    "\n",
    "# caffeine one hot\n",
    "caffeine_smiles = 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C'\n",
    "print(caffeine_smiles.split())\n",
    "\n",
    "caffeine_one_hot = smiles_to_one_hot(caffeine_smiles)\n",
    "\n",
    "print(caffeine_one_hot.shape)  # (120, 56)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(caffeine_one_hot.T,cmap='binary')\n",
    "# plt.xlabel('Tokens')\n",
    "# plt.ylabel('SMILES')\n",
    "\n",
    "\n",
    "caffeine_smiles_pad = caffeine_smiles + \" \" * (max_len - len(caffeine_smiles))\n",
    "\n",
    "plt.title('One-hot encoding for %s'%caffeine_smiles)\n",
    "plt.xticks(np.arange(len(list(caffeine_smiles))),\n",
    "           list(caffeine_smiles), fontsize=8)\n",
    "plt.yticks(np.arange(len(list(SMILES_CHARS))),\n",
    "           list(SMILES_CHARS), fontsize=8)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, SMILES_all, SMILES_labels, flatten=False):\n",
    "        self.molecules_labels = SMILES_labels\n",
    "        self.molecules_all = SMILES_all\n",
    "        self.max_len = 100\n",
    "        self.flatten = flatten\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.molecules_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        molec = self.molecules_all[idx]\n",
    "        label = self.molecules_labels[idx]\n",
    "\n",
    "        molec_one_hot = torch.tensor(smiles_to_one_hot(molec,self.max_len)).double()\n",
    "        molec_one_hot = molec_one_hot.unsqueeze(0).float()\n",
    "            \n",
    "        return molec_one_hot,label, molec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# load the data\n",
    "\n",
    "smiles_all = data.smiles.to_list()\n",
    "logP_all= data.logP.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    smiles_all, logP_all, test_size=0.25, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molec_data_train = SMILESDataset(X_train, torch.tensor(y_train))\n",
    "train_dataloader = DataLoader(molec_data_train, batch_size=1, shuffle=True)\n",
    "\n",
    "for i, data in enumerate(train_dataloader,0):\n",
    "    xi,logP_i, smiles_i = data\n",
    "    print(xi.shape,logP_i,smiles_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem4pb3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
