{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/RodrigoAVargasHdz/CHEM-4PB3/blob/w2024/Course_Notes/Week%208/multi_class_classification.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Lecture (Multi-layer Feed Forward Neural Networks)\n",
    "\n",
    "We can learn a feature representation by repetitively doing.\n",
    "$$ \n",
    " \\mathbf{z}_\\ell = \\sigma(\\mathbf{z}_{\\ell-1}\\mathbf{W}^\\top_\\ell ).\n",
    "$$\n",
    "\n",
    "```python\n",
    "from torch import nn \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 100), # first layer with 100 neurons\n",
    "    nn.SiLU(), # activation function \n",
    "    nn.Linear(100, 100), # second layer with 100 neurons\n",
    "    nn.SiLU(), # activation function \n",
    "    nn.Linear(100, 100), # third layer with 100 neurons\n",
    "    nn.SiLU(), # second layer with 100 neurons\n",
    "    nn.Linear(100, 1) # last layer\n",
    ")\n",
    "```\n",
    "\n",
    "The dimensions of $\\mathbf{W}^\\top_\\ell$ and the flavour of the activation function $\\sigma(\\cdot)$, are consider hyper-parameters; meaning, one have to test various configurations to search for the optimal architecture. \\\n",
    "**Bayesian optimization** have been used to accelerate the search of the optimal neural architecture, [link](https://medium.com/abacus-ai/an-introduction-to-bayesian-optimization-for-neural-architecture-search-d324830ec781).\n",
    "\n",
    "**Diagram**\\\n",
    "<img src=\"https://raw.github.com/RodrigoAVargasHdz/CHEM-4PB3/master/Course_Notes/Figures/MLP_diagram.png\"  width=\"400\" height=\"300\">\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification\n",
    "\n",
    "So far in the course we've covered regression, \n",
    "$$\n",
    "\\mathbf{y} = f_{\\mathbf{\\Theta}}(\\mathbf{x}),\n",
    "$$\n",
    "where, $f_{\\mathbf{\\Theta}}$ is a model parametrized by $\\mathbf{\\Theta}$, and $\\mathbf{y}$ are/is the output-values; $\\mathbf{y} \\in {\\cal R}^{d}$.\n",
    "\n",
    "What happens when $\\mathbf{y}$ has to describe **classes**?  \n",
    "For example, $y = \\text{toxic}$, $y = \\text{acid}$, $y = \\text{cat}$ or $y = \\text{dog}$.\n",
    "\n",
    "Classes are usually described **categorically**.\\\n",
    "One possibility is to parametrize $\\mathbf{y}$ as a vector, where each entry ($y_i$) is the probability of being one of the valid classes. For example, \n",
    "$$\n",
    "y = [p_{\\text{cat}}, p_{\\text{dog}}]\n",
    "$$\n",
    "\n",
    "As example, we will classify images for handwritten digits; $y = [p_{0}, p_{1},p_{2},p_{3},p_{4},\\cdots,p_{9}]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=5, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Digit: %i\" % label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(len(digits))\n",
    "x = digits.images[i]\n",
    "label = digits.target[i]\n",
    "print(f'Digit = %s'%label)\n",
    "print(x)\n",
    "z = np.zeros(10) # 10 total number of digits\n",
    "z[label]=1\n",
    "print('one-hot encoding')\n",
    "print(z)\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.imshow(x, cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into PyTorch\n",
    "1. Split into train and validation\n",
    "2. Create a ```Dataset``` class ([link](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# load the data\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.images, digits.target, test_size=0.25, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_all, img_all_labels, flatten=False, one_hot=False,cnn=False):\n",
    "        self.img_labels = img_all_labels\n",
    "        self.img_all = img_all\n",
    "        self.flatten = flatten\n",
    "        self.one_hot_label = one_hot\n",
    "        self.cnn = cnn\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.img_all[idx]\n",
    "        label = self.img_labels[idx]\n",
    "        \n",
    "        if self.one_hot_label:\n",
    "            label = torch.nn.functional.one_hot(label,num_classes=10)\n",
    "        if self.flatten:\n",
    "            image = torch.flatten(image)\n",
    "        if self.cnn:\n",
    "            image = image.unsqueeze(0).float()\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor(digits.images)\n",
    "labels = torch.tensor(digits.target)\n",
    "data = CustomImageDataset(images,labels)\n",
    "\n",
    "training_data = CustomImageDataset(torch.tensor(X_train),torch.tensor(y_train),False, True)\n",
    "# test_data = CustomImageDataset(torch.tensor(X_test),torch.tensor(y_test))\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=12, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "train_images, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Images batch shape: {train_images.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "print(train_labels[0])\n",
    "print(train_images[0])\n",
    "\n",
    "\n",
    "_,axs = plt.subplots(1,2)\n",
    "axs[0].set_title('Image')\n",
    "axs[0].imshow(train_images[0], cmap=\"gray\")\n",
    "axs[1].set_title('Flat Image')\n",
    "axs[1].imshow(torch.flatten(train_images[0]).unsqueeze(0),\n",
    "              cmap=\"gray\")  # .squeeze(0)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron.\n",
    "  '''\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "        # nn.Flatten(),\n",
    "        nn.Linear(64, 2*64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2*64, 2*64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(2*64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 10)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,training_data,training_epochs=60):\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "  \n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        training_data, batch_size=12, shuffle=True)\n",
    "  \n",
    "    iterator = tqdm.notebook.tqdm(range(training_epochs))\n",
    "    \n",
    "    # Run the training loop (epochs)\n",
    "    loss_trajectory = []\n",
    "    for epoch in iterator:\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = []\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, targets = data\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = loss_function(outputs, targets.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print statistics\n",
    "            # current_loss += loss.item()\n",
    "            current_loss.append(loss.item())\n",
    "        # print('Epoch %s: %.4f +- %.4f'%(epoch,np.array(current_loss).mean(),np.array(current_loss).std()))\n",
    "        iterator.set_postfix(loss=torch.tensor(current_loss).mean())\n",
    "        loss_trajectory.append(current_loss)\n",
    "        # Process is complete.\n",
    "    return loss_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "training_data = CustomImageDataset(torch.tensor(\n",
    "    X_train).float(), torch.tensor(y_train), True, True)\n",
    "\n",
    "\n",
    "print('Total training data: ', X_train.shape[0])\n",
    "loss_trajectory = train(mlp,training_data)\n",
    "print(loss_trajectory)\n",
    "\n",
    "loss_trajectory = np.array(loss_trajectory)\n",
    "mean_loss_itr = np.mean(loss_trajectory,axis=1)\n",
    "std_loss_itr = np.std(loss_trajectory,axis=1)\n",
    "\n",
    "# figure\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.errorbar(np.arange(loss_trajectory.shape[0]),mean_loss_itr,yerr=std_loss_itr)\n",
    "plt.xlabel('Iteration',fontsize=15)\n",
    "plt.ylabel('Cross Entropy (Training)', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction \n",
    "test_data = CustomImageDataset(torch.tensor(\n",
    "    X_test), torch.tensor(y_test), True, True)\n",
    "\n",
    "dataloader = DataLoader(training_data, batch_size=2, shuffle=True)\n",
    "\n",
    "images, labels = next(iter(dataloader))\n",
    "mlp.eval()\n",
    "print(images.shape)\n",
    "pred_labels = mlp(images)\n",
    "print('Exact labels:')\n",
    "print(labels.detach())\n",
    "print('Predicted labels:')\n",
    "print(pred_labels.detach())\n",
    "pred_labels_one_hot = pred_labels.softmax(dim=1).detach()\n",
    "print('Predicted labels (one_hot):')\n",
    "print(pred_labels_one_hot)\n",
    "print(torch.argmax(labels, dim=1), torch.argmax(pred_labels_one_hot, dim=1))\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\n",
    "for ax, image, l in zip(axes, images.detach().numpy().reshape((2,8,8)), labels.detach().numpy()):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Digit: %s\" % np.argmax(l), )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is ```nn.CrossEntropyLoss()```?**\\\n",
    "Cross entropy is used to measure the inefficiency of our predictions used to describe the truth.\n",
    "$$\n",
    "H(\\mathbf{y},\\hat{\\mathbf{y}}) = -\\sum_i \\hat{y}_i\\;\\log(y_i)\n",
    "$$\n",
    "$y$ is the predicted probabilities from our ```model```.\n",
    "To normalize them, we use the ```SoftMax``` transformation,\n",
    "$$\n",
    "y_i = \\frac{\\exp(\\tilde{y}_i)}{\\sum_j^{C} \\exp(\\tilde{y}_j)},\n",
    "$$\n",
    "where $\\tilde{y}_i$ is the unnormalized probabilities for the class $i$; $\\mathbf{\\tilde{y}}=[\\tilde{y}_0,\\cdots,\\tilde{y}_{C}]$.\n",
    "\n",
    "```python\n",
    "def CrossEntropyLoss(pred,target):\n",
    "    log_pred = np.log(pred)\n",
    "    return -np.vdot(target,log_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "z = np.linspace(-10,10)\n",
    "x_,y_ = np.meshgrid(z,z)\n",
    "D = np.column_stack((x_.flatten(),y_.flatten()))\n",
    "print(D.shape)\n",
    "\n",
    "sftmax = softmax(D,axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(9, 4))\n",
    "cs0 = axs[0].contourf(x_, y_, sftmax[:,0].reshape(x_.shape))\n",
    "cbar = fig.colorbar(cs0,ax=axs[0],label=f'p(x=0)')\n",
    "axs[0].set_xlabel(f'$z_0$',fontsize=17)\n",
    "axs[0].set_ylabel(f'$z_1$',fontsize=17)\n",
    "\n",
    "cs1 = axs[1].contourf(x_, y_, sftmax[:,1].reshape(x_.shape))\n",
    "cbar = fig.colorbar(cs1,ax=axs[1],label=f'p(x=1)')\n",
    "axs[1].set_xlabel(f'$z_0$',fontsize=17)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional NeuralNetworks\n",
    "All images are from the following [link](https://github.com/cs231n/cs231n.github.io/blob/master/convolutional-networks.md)\n",
    "\n",
    "<img src=\"https://raw.github.com/cs231n/cs231n.github.io/master/assets/nn1/neural_net2.jpeg\" width=\"500\" height=\"300\">\n",
    "<img src=\"https://raw.github.com/cs231n/cs231n.github.io/master/assets/cnn/depthcol.jpeg\" width=\"500\" height=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 2 * 2, 10) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = self.conv2(x)\n",
    "        # return x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output   # return x for visualization\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two main ingredients of a **CNN layer** are,\n",
    "1. Convolution\n",
    "2. Pooling\n",
    "\n",
    "**Convolution**\n",
    "```python\n",
    "    nn.Conv2d(\n",
    "        in_channels=1, # Number of channels in the input image\n",
    "        out_channels=16, # Number of channels produced by the convolution\n",
    "        kernel_size=5, # Size of the convolving kernel\n",
    "        stride=1,\n",
    "        padding=2, # Zero-padding added to both sides of the input\n",
    "    ),\n",
    "```\n",
    "<img src=\"https://raw.github.com/cs231n/cs231n.github.io/master/assets/cnn/depthcol.jpeg\" width=\"400\" height=\"300\">\n",
    "<img src=\"https://raw.github.com/cs231n/cs231n.github.io/master/assets/nn1/neuron_model.jpeg\" width=\"500\" height=\"300\">\n",
    "\n",
    "[Convolution video](https://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "**Pooling**\n",
    "\n",
    "<img src=\"https://raw.github.com/cs231n/cs231n.github.io/master/assets/cnn/maxpool.jpeg\" width=\"600\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "\n",
    "# prediction\n",
    "training_data = CustomImageDataset(torch.tensor(\n",
    "    X_train), torch.tensor(y_train), False, True, True)\n",
    "\n",
    "dataloader = DataLoader(training_data, batch_size=2, shuffle=True)\n",
    "images, labels = next(iter(dataloader))\n",
    "mlp.eval()\n",
    "pred_labels = cnn(images)\n",
    "print(pred_labels.shape)\n",
    "\n",
    "loss_trajectory_cnn = train(cnn, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trajectory_cnn = np.array(loss_trajectory_cnn)\n",
    "mean_loss_itr_cnn = np.mean(loss_trajectory_cnn, axis=1)\n",
    "std_loss_itr_cnn = np.std(loss_trajectory_cnn, axis=1)\n",
    "print(loss_trajectory_cnn.shape,mean_loss_itr_cnn.shape,std_loss_itr_cnn.shape)\n",
    "\n",
    "# figure\n",
    "fig, ax = plt.subplots(figsize=[8, 6])\n",
    "ax.errorbar(\n",
    "    np.arange(loss_trajectory.shape[0]), mean_loss_itr, yerr=std_loss_itr, label='MLP')\n",
    "ax.errorbar(\n",
    "    np.arange(loss_trajectory_cnn.shape[0]), mean_loss_itr_cnn, yerr=std_loss_itr_cnn, label='CNN')\n",
    "ax.set_xlabel('Iteration', fontsize=15)\n",
    "ax.set_ylabel('Cross Entropy (Training)', fontsize=15)\n",
    "\n",
    "\n",
    "axins = ax.inset_axes([0.5, 0.5, 0.47, 0.47])\n",
    "# axins.imshow(Z2, extent=extent, origin=\"lower\")\n",
    "axins.errorbar(np.arange(40,loss_trajectory.shape[0]), mean_loss_itr[40:], yerr=std_loss_itr[40:], label='MLP')\n",
    "axins.errorbar(np.arange(\n",
    "    40, loss_trajectory_cnn.shape[0]), mean_loss_itr_cnn[40:], yerr=std_loss_itr_cnn[40:], label='CNN')\n",
    "# subregion of the original image\n",
    "x1, x2, y1, y2 = 45, 60, 0.0, 0.03\n",
    "axins.set_xlim(x1, x2)\n",
    "axins.set_ylim(y1, y2)\n",
    "axins.set_xticks(np.arange(40, loss_trajectory.shape[0],2), np.arange(\n",
    "    40, loss_trajectory.shape[0],2))\n",
    "axins.set_xlabel('Iteration', fontsize=15)\n",
    "# axins.set_yticklabels([])\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Why is that MLP is better than the CNN?**\n",
    "* **What happens if we add one extra CNN layer?**\n",
    "  \n",
    "Discuss.\n",
    "\n",
    "<!-- ```python\n",
    "class CNN3L(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3L, self).__init__()        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=32,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )       \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, 3, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(16 * 2 * 2, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # return x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output   # return x for visualization\n",
    "''' -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ```python\n",
    "class CNN3L(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3L, self).__init__()        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=32,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )       \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, 3, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(16 * 2 * 2, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # return x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output   # return x for visualization\n",
    "``` -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_digit(output):\n",
    "    return torch.argmax(output,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_mlp = CustomImageDataset(torch.tensor(\n",
    "    X_test).float(), torch.tensor(y_test), True, True)\n",
    "test_data_cnn = training_data = CustomImageDataset(torch.tensor(\n",
    "    X_test), torch.tensor(y_test), False, True, True)\n",
    "\n",
    "dataloader_mlp = DataLoader(test_data_mlp, batch_size=1, shuffle=True)\n",
    "dataloader_cnn = DataLoader(test_data_cnn, batch_size=1, shuffle=True)\n",
    "\n",
    "mlp.eval()\n",
    "cnn.eval()\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "_, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 10),sharey=True)\n",
    "bad_predictions_mlp = 0\n",
    "bad_predictions_cnn = 0\n",
    "for i, (data_mlp,data_cnn) in enumerate(zip(dataloader_mlp,dataloader_cnn)):\n",
    "    inputs_mlp, targets_mlp = data_mlp\n",
    "    inputs_cnn, targets_cnn = data_cnn\n",
    "    \n",
    "    true_digits_mlp = get_digit(targets_mlp)\n",
    "    true_digits_cnn = get_digit(targets_cnn)\n",
    "    # print(i,inputs_cnn.shape,inputs_mlp.shape)\n",
    "    outputs_mlp = mlp(inputs_mlp)\n",
    "    outputs_mlp = outputs_mlp.softmax(dim=1)\n",
    "    digits_mlp = get_digit(outputs_mlp)\n",
    "    \n",
    "    if true_digits_mlp[0] != digits_mlp[0]:\n",
    "        print('mlp', true_digits_mlp[0],\n",
    "              outputs_mlp[0].detach(), digits_mlp[0])\n",
    "\n",
    "        bad_predictions_mlp += 1\n",
    "\n",
    "    outputs_cnn = cnn(inputs_cnn)\n",
    "    outputs_cnn = outputs_cnn.softmax(dim=1)\n",
    "    digits_cnn = get_digit(outputs_cnn)\n",
    "    if true_digits_cnn[0] != digits_cnn[0]:\n",
    "        print('cnn', true_digits_cnn[0],\n",
    "              outputs_cnn[0].detach(), digits_cnn[0])\n",
    "        bad_predictions_cnn += 1\n",
    "    # print(get_digit(output_mlp))\n",
    "    \n",
    "    axs[0].scatter(true_digits_mlp,digits_mlp,c='tab:orange',marker='o',s=25)\n",
    "    axs[1].scatter(true_digits_cnn,digits_cnn,c='tab:blue',marker='s',s=25)\n",
    "\n",
    "axs[0].set_xticks(np.arange(10),np.arange(10))\n",
    "axs[1].set_xticks(np.arange(10),np.arange(10))\n",
    "axs[0].set_xlabel('MLP predicted digit')\n",
    "axs[1].set_xlabel('CNN predicted digit')\n",
    "axs[0].set_ylabel('True digit')\n",
    "\n",
    "print('Wrong predictions mlp: %s' % bad_predictions_mlp)\n",
    "print('Wrong predictions cnn: %s' % bad_predictions_cnn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem4pb3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
